{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f67Drk6ajuJ",
        "outputId": "c26e641e-5bfd-411f-f518-f1b10ad9814d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive - applicable, if working on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrokuuEudNPU"
      },
      "source": [
        "# Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqwIQWMkZ5PU",
        "outputId": "ba915a5e-56ea-426b-d239-7886041bd21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Best parameters: {'nb__alpha': 0.1, 'nb__fit_prior': True}\n",
            "Best cross-validation score: 87.20%\n",
            "Accuracy on validation set: 86.83%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87      1189\n",
            "           1       0.89      0.84      0.86      1188\n",
            "\n",
            "    accuracy                           0.87      2377\n",
            "   macro avg       0.87      0.87      0.87      2377\n",
            "weighted avg       0.87      0.87      0.87      2377\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1069  120]\n",
            " [ 193  995]]\n",
            "Model saved at /content/drive/MyDrive/D3/naive/gridsearch_pipeline.pkl\n",
            "Accuracy on test set: 87.59%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88      1189\n",
            "           1       0.90      0.84      0.87      1189\n",
            "\n",
            "    accuracy                           0.88      2378\n",
            "   macro avg       0.88      0.88      0.88      2378\n",
            "weighted avg       0.88      0.88      0.88      2378\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1079  110]\n",
            " [ 185 1004]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D3/train_data_split.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D3/val_data_split.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['text']  # Assuming 'title' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['text']  # Assuming 'title' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)\n",
        "\n",
        "# Define the pipeline with TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(max_features=500)),  # Reduce number of features for faster computation\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'nb__alpha': [0.1, 0.5, 1.0],  # Smoothing parameter\n",
        "    'nb__fit_prior': [True, False]  # Whether to learn class prior probabilities or not\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV with cross-validation on training data\n",
        "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and evaluate it on validation data\n",
        "best_pipeline = grid_search.best_estimator_\n",
        "y_pred = best_pipeline.predict(X_val)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.2%}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the best pipeline using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/gridsearch_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(best_pipeline, f)\n",
        "\n",
        "print(f\"Model saved at {model_save_path}\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D3/test_data_split.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Extract features and labels from test data\n",
        "X_test = test_data['text']  # Assuming 'title' is the column containing text data\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    loaded_pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_test_pred = loaded_pipeline.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics for the test set\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_test_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JOJ79g3dvHq"
      },
      "source": [
        "# Bayes Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOoIWdSPdtu5",
        "outputId": "5cfb8eb2-5d53-4504-da3c-5ab94e14fdda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFHbpb5ud3YM",
        "outputId": "6a1a0808-93a4-4771-b2c0-cbfaa7b7a055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best parameters: OrderedDict([('nb__alpha', 0.0016566480893621285), ('nb__fit_prior', False)])\n",
            "Best cross-validation score: 85.49%\n",
            "Accuracy on validation set: 84.54%\n",
            "Classification Report (Validation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       850\n",
            "           1       0.91      0.82      0.86      1168\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.84      0.85      0.84      2018\n",
            "weighted avg       0.85      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix (Validation Set):\n",
            "[[751  99]\n",
            " [213 955]]\n",
            "Model saved at /content/drive/MyDrive/D3/naive/bayes_pipeline.pkl\n",
            "\n",
            "Evaluating on Test Set:\n",
            "Accuracy on test set: 85.28%\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       822\n",
            "           1       0.92      0.83      0.87      1196\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.85      0.86      0.85      2018\n",
            "weighted avg       0.86      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix (Test Set):\n",
            "[[733  89]\n",
            " [208 988]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical\n",
        "import pickle\n",
        "\n",
        "# Paths to data files\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/bayes_pipeline.pkl'\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['text']\n",
        "y_train = train_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['text']\n",
        "y_val = val_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from test data\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Define the pipeline with TF-IDF vectorizer and Naive Bayes model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(max_features=500)),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define the parameter space for Bayesian Optimization\n",
        "param_space = {\n",
        "    'nb__alpha': Real(1e-3, 1.0, prior='log-uniform'),\n",
        "    'nb__fit_prior': Categorical([True, False])\n",
        "}\n",
        "\n",
        "# Perform Bayesian Optimization with cross-validation on training data\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=pipeline,\n",
        "    search_spaces=param_space,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_iter=20,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the Bayesian Optimization\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and evaluate it on validation data\n",
        "best_pipeline = bayes_search.best_estimator_\n",
        "y_pred_val = best_pipeline.predict(X_val)\n",
        "\n",
        "# Print best parameters and evaluation metrics on validation set\n",
        "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {bayes_search.best_score_:.2%}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred_val):.2%}\")\n",
        "print(\"Classification Report (Validation Set):\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "print(\"Confusion Matrix (Validation Set):\")\n",
        "print(confusion_matrix(y_val, y_pred_val))\n",
        "\n",
        "# Save the best model using pickle\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(best_pipeline, f)\n",
        "print(f\"Model saved at {model_save_path}\")\n",
        "\n",
        "# Evaluate the saved model on the test set\n",
        "print(\"\\nEvaluating on Test Set:\")\n",
        "\n",
        "# Load the trained model\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    trained_model = pickle.load(f)\n",
        "\n",
        "# Predict using the loaded model\n",
        "y_pred_test = trained_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance on test set\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test):.2%}\")\n",
        "print(\"Classification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "print(\"Confusion Matrix (Test Set):\")\n",
        "print(confusion_matrix(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ihj8EU2rh3x"
      },
      "source": [
        "# PBT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khArGjMErlyk",
        "outputId": "38b31619-dcbc-4324-eaf2-a8358b4bd738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best alpha: 0.8439575710303715\n",
            "Best fit_prior: False\n",
            "Accuracy on validation set: 84.59%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       850\n",
            "           1       0.91      0.82      0.86      1168\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.84      0.85      0.84      2018\n",
            "weighted avg       0.85      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix:\n",
            "[[753  97]\n",
            " [214 954]]\n",
            "Pipeline saved at /content/drive/MyDrive/D3/naive/pbt_pipeline.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.base import clone\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['text']  # Assuming 'text' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['text']  # Assuming 'text' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Initialize population\n",
        "population_size = 10\n",
        "population = []\n",
        "\n",
        "# Generate initial population with random hyperparameters\n",
        "for _ in range(population_size):\n",
        "    alpha = np.random.uniform(1e-3, 1.0)\n",
        "    fit_prior = np.random.choice([True, False])\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    population.append((model, alpha, fit_prior))\n",
        "\n",
        "# Define number of iterations for PBT\n",
        "iterations = 10\n",
        "\n",
        "# Perform PBT\n",
        "for iteration in range(iterations):\n",
        "    scores = []\n",
        "\n",
        "    # Evaluate each model in the population\n",
        "    for model, alpha, fit_prior in population:\n",
        "        y_pred = model.predict(X_val_tfidf)\n",
        "        score = accuracy_score(y_val, y_pred)\n",
        "        scores.append((score, model, alpha, fit_prior))\n",
        "\n",
        "    # Sort population based on score\n",
        "    scores.sort(reverse=True, key=lambda x: x[0])\n",
        "    top_half = scores[:population_size // 2]\n",
        "    bottom_half = scores[population_size // 2:]\n",
        "\n",
        "    # Update bottom half of the population\n",
        "    for i in range(len(bottom_half)):\n",
        "        _, top_model, top_alpha, top_fit_prior = top_half[i]\n",
        "        _, _, _, _ = bottom_half[i]\n",
        "\n",
        "        # Clone the top model and perturb its hyperparameters\n",
        "        new_alpha = np.clip(top_alpha * np.random.uniform(0.8, 1.2), 1e-3, 1.0)\n",
        "        new_fit_prior = np.random.choice([True, False]) if np.random.rand() < 0.5 else top_fit_prior\n",
        "\n",
        "        new_model = clone(top_model)\n",
        "        new_model.set_params(alpha=new_alpha, fit_prior=new_fit_prior)\n",
        "        new_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        population[population_size // 2 + i] = (new_model, new_alpha, new_fit_prior)\n",
        "\n",
        "# Select the best model from the final population\n",
        "best_model, best_alpha, best_fit_prior = max(population, key=lambda x: accuracy_score(y_val, x[0].predict(X_val_tfidf)))\n",
        "\n",
        "# Define a pipeline with vectorizer and best model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('nb', best_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the entire training data with best hyperparameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Print best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best fit_prior: {best_fit_prior}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the pipeline (including vectorizer and best model) using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/pbt_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved at {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RnoAoOIt1gH",
        "outputId": "99cc6a9b-b4e0-4fc1-8a59-228c57a92e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 85.33%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       822\n",
            "           1       0.92      0.83      0.87      1196\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.85      0.86      0.85      2018\n",
            "weighted avg       0.86      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix:\n",
            "[[734  88]\n",
            " [208 988]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming 'text' is the column containing text data in the test dataset\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "model_load_path = '/content/drive/MyDrive/D3/naive/pbt_pipeline.pkl'\n",
        "with open(model_load_path, 'rb') as f:\n",
        "    pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If8P-enermPM"
      },
      "source": [
        "# Genetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdYYhm9ArsCi",
        "outputId": "78ad8c74-23bf-45ce-eeb6-25c0ab42e637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.25.2)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6lNfVPdt34p",
        "outputId": "57628e04-50ac-4379-f453-f1d904805a6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gen\tnevals\n",
            "0  \t20    \n",
            "1  \t7     \n",
            "2  \t7     \n",
            "3  \t9     \n",
            "4  \t8     \n",
            "5  \t15    \n",
            "6  \t14    \n",
            "7  \t11    \n",
            "8  \t11    \n",
            "9  \t10    \n",
            "10 \t14    \n",
            "11 \t11    \n",
            "12 \t16    \n",
            "13 \t14    \n",
            "14 \t15    \n",
            "15 \t13    \n",
            "16 \t12    \n",
            "17 \t10    \n",
            "18 \t17    \n",
            "19 \t13    \n",
            "20 \t14    \n",
            "21 \t14    \n",
            "22 \t15    \n",
            "23 \t12    \n",
            "24 \t17    \n",
            "25 \t10    \n",
            "26 \t11    \n",
            "27 \t10    \n",
            "28 \t15    \n",
            "29 \t14    \n",
            "30 \t10    \n",
            "31 \t17    \n",
            "32 \t12    \n",
            "33 \t14    \n",
            "34 \t16    \n",
            "35 \t16    \n",
            "36 \t14    \n",
            "37 \t14    \n",
            "38 \t15    \n",
            "39 \t13    \n",
            "40 \t13    \n",
            "Best alpha: 0.5631399429766312\n",
            "Best fit_prior: False\n",
            "Accuracy on validation set: 84.59%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       850\n",
            "           1       0.91      0.82      0.86      1168\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.84      0.85      0.84      2018\n",
            "weighted avg       0.85      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix:\n",
            "[[752  98]\n",
            " [213 955]]\n",
            "Pipeline saved at /content/drive/MyDrive/D3/naive/genetic_pipeline.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['text']  # Assuming 'text' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['text']  # Assuming 'text' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Define the evaluation function for genetic algorithm\n",
        "def evaluate(individual):\n",
        "    alpha = individual[0]\n",
        "    fit_prior = bool(individual[1])\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    return (accuracy,)\n",
        "\n",
        "# Set up the genetic algorithm\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_float\", random.uniform, 1e-3, 1.0)\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_float, toolbox.attr_bool), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "\n",
        "# Custom mutation function to ensure alpha stays within the valid range\n",
        "def custom_mutate(individual):\n",
        "    individual[0] = max(1e-3, min(1.0, individual[0] + random.uniform(-0.05, 0.05)))\n",
        "    individual[1] = random.randint(0, 1)\n",
        "    return individual,\n",
        "\n",
        "toolbox.register(\"mutate\", custom_mutate)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "# Genetic Algorithm parameters\n",
        "population_size = 20\n",
        "generations = 40\n",
        "cxpb, mutpb = 0.5, 0.2\n",
        "\n",
        "# Initialize population\n",
        "population = toolbox.population(n=population_size)\n",
        "\n",
        "# Run the Genetic Algorithm\n",
        "result_population, logbook = algorithms.eaSimple(population, toolbox, cxpb, mutpb, generations,\n",
        "                                                 stats=None, halloffame=None, verbose=True)\n",
        "\n",
        "# Select the best individual\n",
        "best_individual = tools.selBest(result_population, k=1)[0]\n",
        "best_alpha = best_individual[0]\n",
        "best_fit_prior = bool(best_individual[1])\n",
        "\n",
        "# Train the best model on the training data\n",
        "best_model = MultinomialNB(alpha=best_alpha, fit_prior=best_fit_prior)\n",
        "best_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Define a pipeline with vectorizer and best model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('nb', best_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the entire training data with best hyperparameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Print best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best fit_prior: {best_fit_prior}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the pipeline (including vectorizer and best model) using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/genetic_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved at {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55tYqxsCt37K",
        "outputId": "f049d4d1-e1aa-46de-b607-276799c8ef86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 85.28%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       822\n",
            "           1       0.92      0.83      0.87      1196\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.85      0.86      0.85      2018\n",
            "weighted avg       0.86      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix:\n",
            "[[733  89]\n",
            " [208 988]]\n"
          ]
        }
      ],
      "source": [
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming 'text' is the column containing text data in the test dataset\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "model_load_path = '/content/drive/MyDrive/D3/naive/genetic_pipeline.pkl'\n",
        "with open(model_load_path, 'rb') as f:\n",
        "    pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhacKJmmrsnj"
      },
      "source": [
        "# Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-f3vNGFrvzP",
        "outputId": "3ddef048-8771-48c9-e555-7546004c2a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT8JNXIkt_fY",
        "outputId": "a23bd82e-4b95-440d-b0ea-99f7468e2321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 16.00trial/s, best loss: -0.8458870168483648]\n",
            "Best alpha: 0.32537259066901225\n",
            "Best fit_prior: False\n",
            "Accuracy on validation set: 84.59%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83       850\n",
            "           1       0.91      0.82      0.86      1168\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.84      0.85      0.84      2018\n",
            "weighted avg       0.85      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix:\n",
            "[[752  98]\n",
            " [213 955]]\n",
            "Pipeline saved at /content/drive/MyDrive/D3/naive/hyperband_pipeline.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from hyperopt import hp, tpe, Trials, fmin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['text']  # Assuming 'text' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['text']  # Assuming 'text' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Define the evaluation function for hyperopt\n",
        "def evaluate(params):\n",
        "    alpha = params['alpha']\n",
        "    fit_prior = params['fit_prior']\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    return -accuracy  # Minimize negative accuracy (maximize accuracy)\n",
        "\n",
        "# Define the search space\n",
        "space = {\n",
        "    'alpha': hp.loguniform('alpha', np.log(1e-3), np.log(1.0)),  # Smoothing parameter\n",
        "    'fit_prior': hp.choice('fit_prior', [True, False])  # Whether to learn class prior probabilities or not\n",
        "}\n",
        "\n",
        "# Perform hyperparameter optimization with Hyperopt\n",
        "trials = Trials()\n",
        "best = fmin(fn=evaluate,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=100,  # Number of trials\n",
        "            trials=trials)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_alpha = best['alpha']\n",
        "best_fit_prior = [True, False][best['fit_prior']]\n",
        "\n",
        "# Train the best model on the full training data with the best hyperparameters\n",
        "best_model = MultinomialNB(alpha=best_alpha, fit_prior=best_fit_prior)\n",
        "best_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Define a pipeline with vectorizer and best model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('nb', best_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the entire training data with best hyperparameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Print best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best fit_prior: {best_fit_prior}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the pipeline (including vectorizer and best model) using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/hyperband_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved at {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2UmNqO6t_hx",
        "outputId": "723ee8ce-56a9-439f-cfba-24ee05222d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 85.28%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       822\n",
            "           1       0.92      0.83      0.87      1196\n",
            "\n",
            "    accuracy                           0.85      2018\n",
            "   macro avg       0.85      0.86      0.85      2018\n",
            "weighted avg       0.86      0.85      0.85      2018\n",
            "\n",
            "Confusion Matrix:\n",
            "[[733  89]\n",
            " [208 988]]\n"
          ]
        }
      ],
      "source": [
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming 'text' is the column containing text data in the test dataset\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "model_load_path = '/content/drive/MyDrive/D3/naive/hyperband_pipeline.pkl'\n",
        "with open(model_load_path, 'rb') as f:\n",
        "    pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOEA46W523ND"
      },
      "source": [
        "# ydata profling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEdZtO0127Tp",
        "outputId": "d362915d-1d88-4612-b7c8-231856f3e893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ydata-profiling\n",
            "  Downloading ydata_profiling-4.9.0-py2.py3-none-any.whl (356 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.2/356.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.14,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.11.4)\n",
            "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.0.3)\n",
            "Requirement already satisfied: matplotlib<3.10,>=3.5 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.8.2)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (6.0.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.1.4)\n",
            "Collecting visions[type_image_path]<0.7.7,>=0.7.5 (from ydata-profiling)\n",
            "  Downloading visions-0.7.6-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.25.2)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
            "  Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.1/686.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.66.4)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.13.1)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
            "  Downloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.14.2)\n",
            "Collecting typeguard<5,>=3 (from ydata-profiling)\n",
            "  Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wordcloud>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.9.3)\n",
            "Collecting dacite>=1.8 (from ydata-profiling)\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba<1,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.58.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (1.6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<1,>=0.56.0->ydata-profiling) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2024.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2024.7.4)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.6)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (23.2.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
            "Building wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27080 sha256=f698246642bebd81d2a139b716af0ae3d82095010eea0b06419300ba71ddda63\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin, typeguard, multimethod, dacite, imagehash, visions, phik, ydata-profiling\n",
            "Successfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.12 phik-0.12.4 typeguard-4.3.0 visions-0.7.6 ydata-profiling-4.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install ydata_profiling if not already installed\n",
        "!pip install ydata-profiling\n",
        "\n",
        "import pandas as pd\n",
        "from ydata_profiling import ProfileReport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "iLsLHfPQ3UeK",
        "outputId": "91c86e92-3fc5-4abf-c222-8682b9005c9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ydata_profiling/profile_report.py:363: UserWarning: Try running command: 'pip install --upgrade Pillow' to avoid ValueError\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9985d878a75434391fa87c68ef71356",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3974a8e5009548a99cda0c3c6ceaf086",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5edb92a9adf24546acb6793f654d9667",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f309d0f8ae84e47a751470e05451cf1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ydata_profiling/profile_report.py:363: UserWarning: Try running command: 'pip install --upgrade Pillow' to avoid ValueError\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "632b0677cd74496eafc431c4d85d9877",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d0cfa5d43ce4d32a6f9cfeeed80bbbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "386ddcee55d4412b85de86cad451c14c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2b64b26a56f4bbb98c3cb184bd95108",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ydata_profiling/profile_report.py:363: UserWarning: Try running command: 'pip install --upgrade Pillow' to avoid ValueError\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d539b0d777c04d259a60cdd19384aba4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d24d0bae882469aaaa656b0ecd0261c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bff8c5393b8b4c30b201477a862b189d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1545fe57ed064c3fbb620ddac33e12ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Load the CSV files for profiling\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/D3/dataset/train.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/D3/dataset/val.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/D3/dataset/test.csv')\n",
        "\n",
        "# Perform ydata profiling on train dataset\n",
        "train_profile = ProfileReport(train_df, title=\"Train Dataset Profiling Report\")\n",
        "train_profile.to_file(\"/content/drive/MyDrive/D3/dataset/train_profile_report.html\")\n",
        "\n",
        "# Perform ydata profiling on validation dataset\n",
        "val_profile = ProfileReport(val_df, title=\"Validation Dataset Profiling Report\")\n",
        "val_profile.to_file(\"/content/drive/MyDrive/D3/dataset/val_profile_report.html\")\n",
        "\n",
        "# Perform ydata profiling on test dataset\n",
        "test_profile = ProfileReport(test_df, title=\"Test Dataset Profiling Report\")\n",
        "test_profile.to_file(\"/content/drive/MyDrive/D3/dataset/test_profile_report.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO-XBjPc4XcD",
        "outputId": "6072ec8b-d04d-4294-a791-a6f5440d6895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows before removing duplicates: 15848\n",
            "Number of rows after removing duplicates: 13452\n",
            "Train set: (9416, 5)\n",
            "Validation set: (2018, 5)\n",
            "Test set: (2018, 5)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/D3/data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Number of rows before removing duplicate rows\n",
        "rows_before = df.shape[0]\n",
        "\n",
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Number of rows after removing duplicate rows\n",
        "rows_after = df.shape[0]\n",
        "\n",
        "# Split the dataset into train (70%) and temp (30%)\n",
        "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42)\n",
        "\n",
        "# Split the temp dataset into validation (15%) and test (15%)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42)\n",
        "\n",
        "# Save the datasets to CSV files\n",
        "train_df.to_csv('/content/drive/MyDrive/D3/dataset/train.csv', index=False)\n",
        "val_df.to_csv('/content/drive/MyDrive/D3/dataset/val.csv', index=False)\n",
        "test_df.to_csv('/content/drive/MyDrive/D3/dataset/test.csv', index=False)\n",
        "\n",
        "# Display the number of rows before and after removing duplicate rows\n",
        "print(f'Number of rows before removing duplicates: {rows_before}')\n",
        "print(f'Number of rows after removing duplicates: {rows_after}')\n",
        "\n",
        "# Display the shapes of the datasets to verify the splits\n",
        "print(f'Train set: {train_df.shape}')\n",
        "print(f'Validation set: {val_df.shape}')\n",
        "print(f'Test set: {test_df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zvPiqQ_f4osz",
        "outputId": "499b2dfa-7685-4a0b-d469-90e96c7a4847"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 9416,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6008,\n        \"min\": 0,\n        \"max\": 20799,\n        \"num_unique_values\": 9416,\n        \"samples\": [\n          19899,\n          542,\n          6931\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9239,\n        \"samples\": [\n          \"If Donald Trump Pushes on Taiwan, How China Could Push Back - The New York Times\",\n          \"New York Times Admits Key Al Qaeda Role In Aleppo\",\n          \"Neil Gorsuch to Participate in Deciding SCOTUS Gun Rights Hearing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2552,\n        \"samples\": [\n          \"Jennifer Steinhauer\",\n          \"Carol Adl\",\n          \"Jonathan Martin and Alexander Burns\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9260,\n        \"samples\": [\n          \" Trump in the White House By Noam Chomsky\\nNovember 14, CJ Polychroniou : Noam, the unthinkable has happened: in contrast to all forecasts, Donald Trump scored a decisive victory over Hillary Clinton and the man that Michael Moore described as \\u00c2\\u0093wretched, ignorant, dangerous part-time clown and full-time sociopath\\u00c2\\u0094 is the next president of the United States. In your view, what were the deciding factors that led American voters produce the biggest upset in the history of US politics?\\nNoam Chomsky : Before turning to this question, I think it is important to spend a few moments pondering just what happened on November 8, a date that might turn out to be one of the most important in human history, depending on how we react.\\nNo exaggeration.\\nThe most important news of November 8 was barely noted, a fact of some significance in itself.\\nOn November 8, the World Meteorological Organization delivered a report at the international conference on climate change in Morocco, COP22, which was called in order to carry forward the Paris agreements of COP21. The WMO reported that the past five years were the hottest on record. It reported rising sea levels, soon to increase as a result of the unexpectedly rapid melting of polar ice, most ominously the huge Antarctic glaciers. Already Arctic sea ice over the past five years is 28 percent below the average of the previous 29 years, not only raising sea levels but also reducing the cooling effect of polar ice reflection of solar rays, thereby accelerating the grim effects of global warming. The WMO reported further that temperatures are approaching dangerously close to the goal established by COP21, along with other dire reports and forecasts.\\nAnother event took place on November 8, which also may turn out to be of unusual historical significance for reasons that, once again, were barely noted.\\nOn November 8, the most powerful country in world history, which will set its stamp on what comes next, had an election. The outcome placed total control of the government \\u00c2\\u0096 the executive, Congress, the Supreme Court \\u00c2\\u0096 in the hands of the Republican Party, the most dangerous organization in world history.\\nApart from the last phrase, all of this is uncontroversial. The last phrase may seem outlandish, even outrageous. But is it? The facts suggest otherwise. The Party is dedicated to racing as rapidly as possible to destruction of organized human life. There is no historical precedent for such a stand.\\nIs this an exaggeration? Consider what we have just been witnessing.\\nDuring the Republican primaries, every candidate denied that what is happening is happening \\u00c2\\u0096 with the exception of the sensible moderates, like Jeb Bush, who said it\\u00c2\\u0092s all uncertain but we don\\u00c2\\u0092t have to do anything because we\\u00c2\\u0092re producing more natural gas, thanks to fracking. Or John Kasich, who agreed that global warming is taking place but added that \\u00c2\\u0093we are going to burn [coal] in Ohio and we are not going to apologize for it.\\u00c2\\u0094 The winning candidate, now the President-elect, calls for rapid increase in use of fossil fuels, including coal; dismantling of regulations; rejection of help to developing countries that are seeking to move to sustainable energy; and in general racing to the cliff as fast as possible.\\nTrump has already taken steps to dismantle the Environmental Protection Agency by placing in charge of the EPA transition a notorious (and proud) climate change denier, Myron Ebell. Trump\\u00c2\\u0092s top adviser on energy, billionaire oil executive Harold Hamm, announced his expectations, which were predictable: dismantling regulations, tax cuts for the industry (and the wealthy and corporate sector generally), more fossil fuel production, lifting Obama\\u00c2\\u0092s temporary block on the Dakota Access pipeline. The market reacted quickly. Shares in energy corporations boomed, including the world\\u00c2\\u0092s largest coal miner, Peabody Energy, which had filed for bankruptcy, but after Trump\\u00c2\\u0092s victory registered a 50% gain.\\nThe effects of Republican denialism had already been felt. There had been hopes that the COP21 Paris agreement would lead to a verifiable treaty, but any such thoughts were abandoned because the Republican Congress would not accept any binding commitments, so what emerged was a voluntary agreement, evidently much weaker.\\nEffects may soon become even more vividly apparent than they already are. In Bangladesh alone, tens of millions are expected to have to flee from low-lying plains in coming years because of sea level rise and more severe weather, creating a migrant crisis that will make today\\u00c2\\u0092s pale into insignificance. With considerable justice, Bangladesh\\u00c2\\u0092s leading climate scientist says that \\u00c2\\u0093These migrants should have the right to move to the countries from which all these greenhouse gases are coming. Millions should be able to go to the United States.\\u00c2\\u0094 And to the other rich countries that have grown wealthy while bringing about a new geological era, the Anthropocene, marked by radical human transformation of the environment. These catastrophic consequences can only increase, not just in Bangladesh but in all of South Asia as temperatures, already intolerable for the poor, inexorably rise and the Himalayan glaciers melt, threatening the entire water supply. Already in India some 300 million people are reported to lack drinking water. And the effects will reach far beyond.\\nIt is hard to find words to capture the fact that humans are facing the most important question in their history \\u00c2\\u0096 whether organized human life will survive in anything like the form we know \\u00c2\\u0096 and are answering it by accelerating the race to disaster. Similar observations hold for the other huge issue concerning human survival, the threat of nuclear destruction that has been looming over our heads for 70 years, and is now increasing.\\nIt is no less difficult to find words to capture the utterly astonishing fact that in all of the massive coverage of the electoral extravaganza, none of this receives more than passing mention. At least I am at a loss to find appropriate words.\\nTurning finally to the question raised, to be precise it appears that Clinton received a slight majority of the vote. The apparent decisive victory has to do with curious features of American politics: among other factors, the electoral college residue of the founding of the country as an alliance of separate states; the winner-take-all system in each state; arrangement of congressional districts (sometimes by gerrymandering) to provide greater weight to rural votes (in past elections, probably this one too, Democrats have had a comfortable margin of victory in popular vote for the House but hold a minority of seats); the very high rate of abstention (usually close to half in presidential elections, this one too). Of some significance for the future is the fact that in the 18-25 range, Clinton won handily, and Sanders had an even higher level of support. How much this matters depends on what kind of future humanity will face.\\nAccording to current information, Trump broke all records in the support he received from white voters, working class and lower middle class, particularly in the $50,000 to $90,000 income range, rural and suburban, primarily those without college education. These groups share the anger throughout the West at the centrist establishment, revealed as well in the unanticipated Brexit vote and the collapse of centrist parties in continental Europe. The angry and disaffected are victims of the neoliberal policies of the past generation, the policies described in congressional testimony by Fed chair Alan Greenspan \\u00c2\\u0096 St. Alan as he was called reverentially by the economics profession and other admirers until the miraculous economy he was supervising crashed in 2007-8, threatening to bring the whole world economy down with it. As Greenspan explained during his glory days, his successes in economic management were based substantially on \\u00c2\\u0093growing worker insecurity.\\u00c2\\u0094 Intimidated working people would not ask for higher wages, benefits, and security but would be satisfied with the stagnating wages and reduced benefits that signal a healthy economy by neoliberal standards.\\nWorking people who have been the subjects of these experiments in economic theory are, oddly, not particularly happy about the outcome. They are not, for example, overjoyed at the fact that in 2007, at the peak of the neoliberal miracle, real wages for non-supervisory workers were lower than they had been years earlier, or that real wages for male workers are about at 1960s levels while spectacular gains have gone to the pockets of a very few at the top, disproportionately a fraction of 1%. Not the result of market forces, achievement, or merit, but rather of definite policy decisions, matters reviewed carefully by economist Dean Baker in recently published work.\\nThe fate of the minimum wage illustrates what has been happening. Through the periods of high and egalitarian growth in the \\u00c2\\u009150s and \\u00c2\\u009160s, the minimum wage \\u00c2\\u0096 which sets a floor for other wages \\u00c2\\u0096 tracked productivity. That ended with the onset of neoliberal doctrine. Since then the minimum wage has stagnated (in real value). Had it continued as before, it would probably be close to $20 per hour. Today it is considered a political revolution to raise it to $15.\\nWith all the talk of near-full employment today, labor force participation remains below the earlier norm. And for a working man, there is a great difference between a steady job in manufacturing with union wages and benefits, as in earlier years, and a temporary job with little security in some service profession. Apart from wages, benefits, and security, there is a loss of dignity, of hope for the future, of a sense that this is a world in which I belong and play a worthwhile role.\\nThe impact is captured well in Arlie Hochschild\\u00c2\\u0092s sensitive and illuminating portrayal of a Trump stronghold in Louisiana, where she lived and worked for many years. She uses the image of a line in which these people are standing, expecting to move forward steadily as they work hard and keep to all the conventional values. But their position in the line has stalled. Ahead of them, they see people leaping forward, but that does not cause much distress, because it is \\u00c2\\u0093the American way\\u00c2\\u0094 for (alleged) merit to be rewarded. What does cause real distress is what is happening behind them. Undeserving people who do not follow the rules are being moved in front of them by federal government programs designed to benefit African-Americans, immigrants, and others they often regard with contempt. All of this is exacerbated by Reagan\\u00c2\\u0092s racist fabrications about strapping young bucks and welfare queens (by implication Black) stealing your hard-earned money, and other fantasies \\u00c2\\u0097 which are sometimes tinged with shreds of reality, as is usually the case with ugly and dangerous concoctions designed to deflect attention from the real agents of distress to easy scapegoats.\\nSometimes failure to explain, itself a form of contempt, plays a role. I once met a house painter in Boston who had turned bitterly against the evil government after a Washington bureaucrat who knew nothing about painting organized a meeting of painting contractors to inform them that they could no longer use lead paint, the only kind that works, as they all knew but the suit didn\\u00c2\\u0092t understand. That destroyed his small business, compelling him to paint houses on his own with substandard stuff forced on him by government elites. Sometimes there are also some reasons. Hochschild describes a man whose family and friends are suffering bitterly from the lethal effects of chemical pollution but who despises the government, and the \\u00c2\\u0093liberal elites,\\u00c2\\u0094 because for him, the EPA means some ignorant guy who tells him he can\\u00c2\\u0092t fish but does nothing about the chemical plants.\\nThese are just samples of the real lives of Trump supporters, who are deluded to believe that Trump will do something to remedy their plight, though the merest look at his fiscal and other proposals demonstrates the opposite \\u00c2\\u0096 posing a task for activists who hope to fend off the worst and to advance desperately needed changes.\\nExit polls reveal that the passionate support for Trump was inspired primarily by the belief that he represented change, while Clinton was perceived as the candidate who would perpetuate their distress. The \\u00c2\\u0093change\\u00c2\\u0094 that Trump is likely to bring will be harmful or worse, but it is understandable that the consequences are not clear to isolated people in an atomized society lacking the kinds of associations (like unions) that can educate and organize. That is a crucial difference between today\\u00c2\\u0092s despair and the generally hopeful attitudes of many working people under much greater duress during the great depression of the 1930s.\\nThere are other factors in Trump\\u00c2\\u0092s success. Comparative studies show that doctrines of White Supremacy have had an even more powerful grip on American culture than in South Africa, and it\\u00c2\\u0092s no secret that the white population is declining. In a decade or two whites are projected to be a minority of the work force, and not too much later a minority of the population. The traditional conservative culture is also perceived as under attack by the successes of \\u00c2\\u0093identity politics,\\u00c2\\u0094 regarded as the province of elites who have only contempt for hard-working patriotic church-going Americans with real family values whose country is disappearing before their eyes.\\nIt is worth remembering that before World War II, though it had long been the richest country in the world, the US was not a major player in global affairs and was also something of a cultural backwater. Someone who wanted to study physics would go to Germany. An aspiring writer or artist would go to Paris. That changed radically with World War II, for obvious reasons, but only for part of the population. Much remained culturally traditional. To mention one example of great significance, one of the difficulties in raising public concern over the very severe threats of global warming is that 40% of the population do not see why it is a problem, since Christ is returning in a few decades. About the same percentage believe that the world was created a few thousand years ago. If science conflicts with the Bible, so much the worse for science. It would be hard to find an analogue in other societies.\\nThe Democratic party abandoned any real concern for working people by the 1970s, and they have therefore been drawn to the ranks of their bitter class enemies, who at least pretend to speak their language \\u00c2\\u0096 Reagan\\u00c2\\u0092s folksy style with little jokes while eating jelly beans, W. Bush\\u00c2\\u0092s carefully cultivated image of a regular guy you could meet in a bar who loved to cut brush on the ranch in 100 degree heat and his probably faked mispronunciations (it\\u00c2\\u0092s unlikely that he talked like that at Yale), and now Trump, who gives voice to people with legitimate grievances who have lost not just jobs but also a sense of personal self-worth; and who rails against the government that they perceive as having undermined their lives (not without reason).\\nOne of the great achievements of the doctrinal system has been to divert anger from the corporate sector to the government that implements the programs it designs, such as the highly protectionist corporate/investor rights agreements that are uniformly mis-described as \\u00c2\\u0093free trade agreements\\u00c2\\u0094 in the media and commentary. With all its flaws, the government is to some extent under popular influence and control, unlike the corporate sector. It is highly advantageous for the business world to foster hatred for pointy-headed government bureaucrats and to drive out of people\\u00c2\\u0092s minds the subversive idea that the government might become an instrument of popular will, a government of, by, and for the people.\\nIs Trump representing a new movement in American politics, or was the outcome of this election primarily a rejection of Hillary Clinton by voters who hate the Clintons and are fed-up with \\u00c2\\u0093politics as usual?\\u00c2\\u0094\\nIt\\u00c2\\u0092s by no means new. Both political parties have moved to the right during the neoliberal period. Today\\u00c2\\u0092s New Democrats are pretty much what used to be called \\u00c2\\u0093moderate Republicans.\\u00c2\\u0094 The \\u00c2\\u0093political revolution\\u00c2\\u0094 that Bernie Sanders called for, rightly, would not have greatly surprised Dwight Eisenhower. The Republicans have moved so far to dedication to the wealthy and the corporate sector that they cannot hope to get votes on their actual programs, and have turned to mobilizing sectors of the population that have always been there but not as an organized political force: evangelicals, nativists, racists, and the victims of the forms of globalization designed to set working people around the world in competition with one another while protecting the privileged and undermining the legal and other measures that provided working people with some protection and with ways to influence decision-making in the closely linked public and private sectors, notably with effective labor unions.\\nThe consequences have been evident in recent Republican primaries. Every candidate that has emerged from the base \\u00c2\\u0096 Bachmann, Cain, Santorum, \\u00c2\\u0097 has been so extreme that the Republican establishment had to use its ample resources to beat them down. The difference in 2016 is that the establishment failed, much to its chagrin, as we have seen.\\nDeservedly or not, Clinton represented the policies that were feared and hated while Trump was seen as the symbol of \\u00c2\\u0093change\\u00c2\\u0094 \\u00c2\\u0096 change of what kind requires a careful look at his actual proposals, something largely missing in what reached the public. The campaign itself was remarkable in its avoidance of issues, and media commentary generally complied, keeping to the concept that true objectivity means reporting accurately what is \\u00c2\\u0093within the beltway\\u00c2\\u0094 but not venturing beyond.\\nTrump said following the outcome of the election that he \\u00c2\\u0093will represent all Americans.\\u00c2\\u0094 How is be going to do that when the nation is so divided and he has already expressed deep hatred for many groups in the United States, including women and minorities? Do you see any resemblance between Brexit and Donald Trump\\u00c2\\u0092s victory?\\nThere are definite similarities to Brexit, and also to the rise of the ultranationalist far-right parties in Europe \\u00c2\\u0096 whose leaders were quick to congratulate Trump on his victory, perceiving him as one of their own: Farrage, Le Pen, Orban, and others like them. And these developments are quite frightening. A look at the polls in Austria and Germany \\u00c2\\u0096 Austria and Germany \\u00c2\\u0096 cannot fail to evoke unpleasant memories for those familiar with the 1930s, even more so for those who watched directly, as I did as a child. I can still recall listening to Hitler\\u00c2\\u0092s speeches, not understanding the words though the tone and audience reaction were chilling enough. The first article that I remember writing was in February 1939, after the fall of Barcelona, on the seemingly inexorable spread of the fascist plague. And by strange coincidence, it was in Barcelona that my wife and I watched Tuesday\\u00c2\\u0092s events.\\nAs to how Trump will handle what he has brought forth \\u00c2\\u0096 not created, but brought forth \\u00c2\\u0096 we cannot say. Perhaps his most striking characteristic is unpredictability. A lot will depend on the reactions of those appalled by his performance and the visions he has projected, such as they are.\\nTrump has no identifiable political ideology guiding his stance on economic, social, and political issues, yet there are clear authoritarian tendencies in his behavior. Therefore, do you find any validity behind the claims that Trump may represent the emergence of \\u00c2\\u0093fascism with a friendly face?\\u00c2\\u0094 in the United States?\\nFor many years I have been writing and speaking about the danger of the rise of an honest and charismatic ideologue in the United States, someone who could exploit the fear and anger that has long been boiling in much of the society, and who could direct it away from the actual agents of malaise to vulnerable targets. That could indeed lead to what sociologist Bertram Gross called \\u00c2\\u0093friendly fascism\\u00c2\\u0094 in a perceptive study 35 years ago. But that requires an honest ideologue, a Hitler type, not someone whose only detectable ideology is Me. The dangers however have been real for many years, perhaps even more so in the light of the forces that Trump has unleashed.\\nWith the Republicans in the White House, but also controlling both houses and the future shape of the Supreme Court, what will America look like for at least the next four years?\\nA good deal depends on his appointments and circle of advisers. Early indications are unattractive, to put it mildly.\\nThe Supreme Court will be in the hands of reactionaries for many years, with predictable consequences. If Trump follows through on his Paul Ryan-style fiscal programs, there will be huge benefits for the very rich \\u00c2\\u0096 estimated by the Tax Policy Center as a tax cut of over 14% for the top 0.1% and a substantial cut more generally at the upper end of the income scale, but with virtually no tax relief for others, who will also face major new burdens. The respected economics correspondent of the Financial Times, Martin Wolf, writes that \\u00c2\\u0093The tax proposals would shower huge benefits on already rich Americans such as Mr Trump,\\u00c2\\u0094 while leaving others in the lurch, including of course his popular constituency. The immediate reaction of the business world reveals that big pharma, Wall Street, military industry, energy industries, and other such wonderful institutions expect a very bright future.\\nOne positive development might be the infrastructure program that Trump has promised while (along with much reporting and commentary) concealing the fact that it is essentially the Obama stimulus program that would have been of great benefit to the economy and to the society generally, but was killed by the Republican Congress on the pretext that it would explode the deficit. While that charge was spurious at the time, given the very low interest rates, it holds in spades for Trump\\u00c2\\u0092s program, now accompanied by radical tax cuts for the rich and corporate sector and increased Pentagon spending.\\nThere is, however, an escape, provided by Dick Cheney when he explained to Bush\\u00c2\\u0092s Treasury Secretary Paul O\\u00c2\\u0092Neill that \\u00c2\\u0093Reagan proved that deficits don\\u00c2\\u0092t matter\\u00c2\\u0094 \\u00c2\\u0096 meaning deficits that we Republicans create in order to gain popular support, leaving it to someone else, preferably Democrats, to somehow clean up the mess. The technique might work, for a while at least.\\nThere are also many questions about foreign policy consequences, mostly unanswered.\\nThere is mutual admiration between Trump and Putin. How likely is it therefore that we may see a new era in US-Russia relations?\\nOne hopeful prospect is that there might be reduction of the very dangerous and mounting tensions at the Russian border: note \\u00c2\\u0093the Russian border,\\u00c2\\u0094 not the Mexican border. Thereby lies a tale that we cannot go into here. It is also possible that Europe might distance itself from Trump\\u00c2\\u0092s America, as already suggested by Chancellor Merkel and other European leaders \\u00c2\\u0096 and from the British voice of American power, after Brexit. That might possibly lead to European efforts to defuse the tensions, and perhaps even efforts to move towards something like Mikhail Gorbachev\\u00c2\\u0092s vision of an integrated Eurasian security system without military alliances, rejected by the US in favor of NATO expansion, a vision revived recently by Putin, whether seriously or not we do not know since the gesture was dismissed.\\nIs US foreign policy under a Trump administration likely to be more or less militaristic than what we have seen under the Obama or even the G.W. Bush administrations?\\nI don\\u00c2\\u0092t think one can answer with any confidence. Trump is too unpredictable. There are too many open questions. What we can say is that popular mobilization and activism, properly organized and conducted, can make a large difference.\\nAnd we should bear in mind that the stakes are very large, as I remarked at the outset.\",\n          \"Microsoft founder Bill Gates called for a robot tax to offset the loss of jobs done by humans as a result of advancements in automation during an interview with Quartz. [\\u00e2\\u0080\\u009cCertainly there will be taxes that relate to automation. Right now, the human worker who does, say, $50, 000 worth of work in a factory, that income is taxed and you get income tax, social security tax, all those things,\\u00e2\\u0080\\u009d declared Gates. \\u00e2\\u0080\\u009cIf a robot comes in to do the same thing, you\\u00e2\\u0080\\u0099d think that we\\u00e2\\u0080\\u0099d tax the robot at a similar level. \\u00e2\\u0080\\u009d  \\u00e2\\u0080\\u009cThere are many ways to take that extra productivity and generate more taxes. Exactly how you\\u00e2\\u0080\\u0099d do it, measure it, you know, it\\u00e2\\u0080\\u0099s interesting for people to start talking about now,\\u00e2\\u0080\\u009d he continued. \\u00e2\\u0080\\u009cSome of it can come on the profits that are generated by the   efficiency there. Some of it can come directly in some type of robot tax. I don\\u00e2\\u0080\\u0099t think the robot companies are going to be outraged that there might be a tax. It\\u00e2\\u0080\\u0099s OK. \\u00e2\\u0080\\u009d Gates added that \\u00e2\\u0080\\u009cyou ought to be willing to raise the tax level and even slow down the speed of that adoption somewhat to figure out, \\u00e2\\u0080\\u0098OK, what about the communities where this has a particularly big impact? Which transition programs have worked and what type of funding do those require? \\u00e2\\u0080\\u0099\\u00e2\\u0080\\u009d \\u00e2\\u0080\\u009cYou cross the threshold of   of certain activities all sort of at once,\\u00e2\\u0080\\u009d Gates concluded. \\u00e2\\u0080\\u009cSo, you know, warehouse work, driving, room cleanup, there\\u00e2\\u0080\\u0099s quite a few things that are meaningful job categories that, certainly in the next 20 years, being thoughtful about that extra supply is a net benefit. It\\u00e2\\u0080\\u0099s important to have the policies to go with that. \\u00e2\\u0080\\u009d Billionaire and entrepreneur Mark Cuban also claimed robots are going to \\u00e2\\u0080\\u009ccause unemployment,\\u00e2\\u0080\\u009d posting, \\u00e2\\u0080\\u009cAutomation is going to cause unemployment and we need to prepare for it,\\u00e2\\u0080\\u009d to Twitter on Sunday. Last week, Tesla and SpaceX founder Elon Musk warned that deep A. I. could potentially be dangerous to the human race, who he described as already  . \\u00e2\\u0080\\u009cOne of the most troubling questions is artificial intelligence. I don\\u00e2\\u0080\\u0099t mean narrow A. I   \\u00e2\\u0080\\u0094   deep artificial intelligence, where you can have AI which is much smarter than the smartest human on earth,\\u00e2\\u0080\\u009d proclaimed Musk during the World Government Summit in Dubai. \\u00e2\\u0080\\u009cThis is a dangerous situation. \\u00e2\\u0080\\u009d \\u00e2\\u0080\\u009cPay close attention to the development of artificial intelligence,\\u00e2\\u0080\\u009d he continued. \\u00e2\\u0080\\u009cMake sure researchers don\\u00e2\\u0080\\u0099t get carried away. Scientists get so engrossed in their work they don\\u00e2\\u0080\\u0099t realize what they are doing. \\u00e2\\u0080\\u009d In November, Musk also predicted that automated robots would lead to mass unemployment, which he claimed could eventually create a universal wage from the government. Charlie Nash is a reporter for Breitbart Tech. You can follow him on Twitter @MrNashington or like his page at Facebook.\",\n          \"\\nA new Wikileaks email just exposed that Hillary Clinton loves to drink. This is coming from Wikileaks. In one telling line in a new WikiLeaks drop, John Podesta and communications aide Jennifer Palmieri are caught discussing whether to \\u00e2\\u0080\\u009csober her up some.\\u00e2\\u0080\\u009d\\nA new WikiLeaks email ID 25842 reveals that Hillary was boozed up until 4:30 in the afternoon.\\n\\u00e2\\u0080\\u009cShould I call her and talk this through or better leave with you?\\u00e2\\u0080\\u009d Podesta asked at 2 p.m. \\u00e2\\u0080\\u009cI\\u00e2\\u0080\\u0099m worried she\\u00e2\\u0080\\u0099ll get on with Cheryl [Mills] and we\\u00e2\\u0080\\u0099ll end up in a bad place.\\u00e2\\u0080\\u009d\\nThen Palmieri responds to Podesta:\\n\\u00e2\\u0080\\u009c I think you should call her and sober her up some \\u00e2\\u0080\\u009d, she said.\\nWe need to get this out there! Even her own staff think that she is a drunk.\\nCheck out this video below of Hillary Clinton drunk.\\nHillary is not a good choice for President. She is not going to make it through the stress and the negotiations.\\nGod bless Trump for standing up to this drunkard. Trump doesn\\u00e2\\u0080\\u0099t drink. Should we elect an alcoholic as president?\\n\\n\\nSource \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-36fad58f-e8b6-481e-abcd-ab8561e9781e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1155</th>\n",
              "      <td>10724</td>\n",
              "      <td>Trumpâs FIRST Order: Anyone Burning An Ameri...</td>\n",
              "      <td>Martin Walsh</td>\n",
              "      <td>\\nPosted by Martin Walsh | Nov 11, 2016 | Libe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15028</th>\n",
              "      <td>7200</td>\n",
              "      <td>Global Migration Meets Magic in Mohsin Hamidâ...</td>\n",
              "      <td>Alexandra Alter</td>\n",
              "      <td>In an unnamed,   city in the Muslim world, two...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6455</th>\n",
              "      <td>19242</td>\n",
              "      <td>WATCH: Gingrich Accuses Megyn Kelly Of Being â...</td>\n",
              "      <td>Davis</td>\n",
              "      <td>Hillary Howls in Laughter About Radical Muslim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7917</th>\n",
              "      <td>11695</td>\n",
              "      <td>Badass Patriot Has MASSIVE Surprise For Thieve...</td>\n",
              "      <td>Amanda Shea</td>\n",
              "      <td>Badass Patriot Has MASSIVE Surprise For Thieve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1728</th>\n",
              "      <td>2205</td>\n",
              "      <td>James Wesley Rawles: âDouble Up On Your Prep...</td>\n",
              "      <td>Mac Slavo</td>\n",
              "      <td>\\nEnjoy your turkey, family events and holiday...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36fad58f-e8b6-481e-abcd-ab8561e9781e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36fad58f-e8b6-481e-abcd-ab8561e9781e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36fad58f-e8b6-481e-abcd-ab8561e9781e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c9016b8-0315-49c5-9107-3ccf536c6735\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c9016b8-0315-49c5-9107-3ccf536c6735')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c9016b8-0315-49c5-9107-3ccf536c6735 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          id                                              title  \\\n",
              "1155   10724  Trumpâs FIRST Order: Anyone Burning An Ameri...   \n",
              "15028   7200  Global Migration Meets Magic in Mohsin Hamidâ...   \n",
              "6455   19242  WATCH: Gingrich Accuses Megyn Kelly Of Being â...   \n",
              "7917   11695  Badass Patriot Has MASSIVE Surprise For Thieve...   \n",
              "1728    2205  James Wesley Rawles: âDouble Up On Your Prep...   \n",
              "\n",
              "                author                                               text  \\\n",
              "1155      Martin Walsh  \\nPosted by Martin Walsh | Nov 11, 2016 | Libe...   \n",
              "15028  Alexandra Alter  In an unnamed,   city in the Muslim world, two...   \n",
              "6455             Davis  Hillary Howls in Laughter About Radical Muslim...   \n",
              "7917       Amanda Shea  Badass Patriot Has MASSIVE Surprise For Thieve...   \n",
              "1728         Mac Slavo  \\nEnjoy your turkey, family events and holiday...   \n",
              "\n",
              "       label  \n",
              "1155       1  \n",
              "15028      0  \n",
              "6455       1  \n",
              "7917       1  \n",
              "1728       1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bunuISAkr273",
        "outputId": "7f5c53f0-23a3-4735-f6fe-96a5f2148453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in train dataset: 9416\n",
            "Number of rows in validation dataset: 2018\n",
            "Number of rows in test dataset: 2018\n",
            "Number of rows in combined dataset: 13452\n",
            "Combined dataset saved at /content/drive/MyDrive/D3/combined_data.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training, validation, and test datasets\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Print the number of rows in each dataset before combining\n",
        "print(f\"Number of rows in train dataset: {len(train_data)}\")\n",
        "print(f\"Number of rows in validation dataset: {len(val_data)}\")\n",
        "print(f\"Number of rows in test dataset: {len(test_data)}\")\n",
        "\n",
        "# Combine the datasets\n",
        "combined_data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
        "\n",
        "# Print the number of rows in the combined dataset\n",
        "print(f\"Number of rows in combined dataset: {len(combined_data)}\")\n",
        "\n",
        "# Save the combined dataset to a CSV file\n",
        "combined_data_path = '/content/drive/MyDrive/D3/combined_data.csv'\n",
        "combined_data.to_csv(combined_data_path, index=False)\n",
        "\n",
        "print(f\"Combined dataset saved at {combined_data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LqhU8e6940G"
      },
      "source": [
        "# BERT + GSCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "768cef91b36d43c7bbdd71c511a00a07",
            "a02b1c7410974b8f97cbf7732705e1ca",
            "0550d16471cd4783851b44e041cbcdd6",
            "6d1139ecfcd242159c43faa54da75447",
            "a604b0300cd747438fac198673940b13",
            "59fb7ac14709495e86f29eede0dde3b7",
            "003f8991096744bd9946ebce1ea3d91c",
            "2cc5dd67b22d40c3aec85363377455fd",
            "a9375c0c8b8a4481a4c156f076f5261b",
            "c41b84d9f74f44abb558c22e37f59171",
            "a1a731d2f363454e8fe6c0b9f7420f87",
            "98241dc3f5c842748ecc930a2c15e3b7",
            "a174556292b4491798f11dc02f004961",
            "7c9f96ab309d48ffbd0dbc4b36bbed3e",
            "4c885e3bc2994fcfa1ab39bcca4e335c",
            "045de8e7f0054b238878cac135b1989f",
            "66eb07f83f1949aa860866da570835c4",
            "d859f836a3da436282e5524cf31b783a",
            "82bb2d43371e4f35a168984c21b3d283",
            "2ab261f382d64c8aa6e8ac940676373e",
            "7b79740a45424f9086ef15b8a29055a3",
            "cdd4936876a7457ca58306598604ce1b",
            "13ae52e633694103876da0e2f74437af",
            "419f8140de0847a795964abb401aee63",
            "9aaa2cc7c550454e9f0944bd6b445a60",
            "5a6e0a8a21f7484e9841dd615dfcdf1c",
            "bb734d0d7b864a7b8341cbf667119e2f",
            "3bc570c9a0a34dc0a76abea559b511bf",
            "adf6f98047004919aad42f804f22d24f",
            "2472382ab5ea49ad892ceb21830b71fc",
            "d0ea6dea36874649a0bcd5bd46fa0751",
            "abde59b07c8a47b7b4c50556f8440c55",
            "838e080ea88445ccaa7c2dfa68e47b41",
            "4ec0390564b348e7b0df83ba13fe0bdb",
            "d8aef8e1beaf46cfb201137e7450d3cc",
            "8c5e7dc644344d9eb209ece03665d175",
            "9df5993ed4924f1b97cea32fe12f54ce",
            "c1b2856b14d84a028e766b96e4292275",
            "98f25e63489e4d579de917f04fe48592",
            "2e256c93d9ee4df595bc2df1bff5798e",
            "9fec4d8f088349d1832e34416209799b",
            "8af8e9eef5594a468eb77e37ddc8eae7",
            "1c4bec17d33f49d992307b972ad3cb28",
            "fb18ba3dea24467fa21102d89efddc4b",
            "6851f1e0ca7b4cefb2c827ecd08f26a1",
            "950a24ccbff0437492b48e5d653634cc",
            "ef439366f90748d9b13294de11d1cc79",
            "b398fcf807d443e2bc812900a46d4ad6",
            "5d98a015b12d4c79b09962ed30e7ec0b",
            "aa553849733d413d82aac85778459e29",
            "8d82ccf379604810957b35130a9ff0e5",
            "6af2136c37ab4b4ca3b88f5985232299",
            "54aa16bb9f0b44cab597a91ea087d4ab",
            "4f7afef1c86f4e6f91533ced83d16737",
            "056155d28f574b6a967a0970079bd4c8"
          ]
        },
        "id": "FGDZeYDtELQx",
        "outputId": "1e7320af-c212-4e7a-a8c3-18590c341099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "768cef91b36d43c7bbdd71c511a00a07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98241dc3f5c842748ecc930a2c15e3b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13ae52e633694103876da0e2f74437af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ec0390564b348e7b0df83ba13fe0bdb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6851f1e0ca7b4cefb2c827ecd08f26a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 50.46%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67      1189\n",
            "           1       1.00      0.01      0.02      1189\n",
            "\n",
            "    accuracy                           0.50      2378\n",
            "   macro avg       0.75      0.50      0.34      2378\n",
            "weighted avg       0.75      0.50      0.34      2378\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1189    0]\n",
            " [1178   11]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pickle\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D3/test_data_split.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Extract features and labels from test data\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load and prepare BERT model and tokenizer\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.classifier = torch.nn.Linear(768, 2)  # Adjust according to your architecture\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return self.softmax(logits)\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Instantiate the classifier\n",
        "bert_classifier = BERTClassifier(bert_model)\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load('/content/drive/MyDrive/D3/bert_model.pth')\n",
        "\n",
        "# Rename keys if needed (optional)\n",
        "# state_dict['classifier.weight'] = state_dict.pop('fc1.weight')\n",
        "# state_dict['classifier.bias'] = state_dict.pop('fc1.bias')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "bert_classifier.load_state_dict(state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "bert_classifier.eval()\n",
        "\n",
        "# Function to make predictions with BERT\n",
        "def predict_bert(texts, batch_size=32):\n",
        "    predictions = []\n",
        "    num_batches = int(np.ceil(len(texts) / batch_size))\n",
        "    for i in range(num_batches):\n",
        "        batch_texts = texts[i*batch_size:(i+1)*batch_size]\n",
        "        batch_texts = batch_texts.tolist()\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_classifier(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "        logits = outputs\n",
        "        batch_predictions = torch.argmax(logits, dim=1).numpy()\n",
        "        predictions.extend(batch_predictions)\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Load the saved Naive Bayes pipeline\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/gridsearch_pipeline.pkl'\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    nb_pipeline = pickle.load(f)\n",
        "\n",
        "# Get predictions from both models\n",
        "nb_predictions = nb_pipeline.predict(X_test)\n",
        "bert_predictions = predict_bert(X_test)\n",
        "\n",
        "# Combine predictions using majority voting\n",
        "combined_predictions = np.array([np.bincount([nb_pred, bert_pred]).argmax() for nb_pred, bert_pred in zip(nb_predictions, bert_predictions)])\n",
        "\n",
        "# Print evaluation metrics for the test set\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, combined_predictions):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, combined_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, combined_predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp5jEnY9_9k0"
      },
      "source": [
        "# Test with Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UORojJziVJwv",
        "outputId": "f61296e5-db54-406b-d4fc-4a0e0638b6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined Accuracy: 52.50%\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.69       520\n",
            "           1       1.00      0.01      0.02       480\n",
            "\n",
            "    accuracy                           0.53      1000\n",
            "   macro avg       0.76      0.51      0.35      1000\n",
            "weighted avg       0.75      0.53      0.37      1000\n",
            "\n",
            "Confusion Matrix\n",
            "[[520   0]\n",
            " [475   5]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "# Function to clear memory\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Load the Naive Bayes pipeline\n",
        "model_save_path = '/content/drive/MyDrive/D3/naive/gridsearch_pipeline.pkl'\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    nb_pipeline = pickle.load(f)\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D3/test_data_split.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Sample a subset from the test data\n",
        "subset_size = 1000  # Define the size of the subset\n",
        "subset_data = test_data.sample(n=subset_size, random_state=42)\n",
        "\n",
        "# Extract features and labels from the subset\n",
        "X_test = subset_data['text']\n",
        "y_test = subset_data['label'].astype(int)\n",
        "\n",
        "# Load and prepare BERT model and tokenizer\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.classifier = torch.nn.Linear(768, 2)\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return self.softmax(logits)\n",
        "\n",
        "# Load BERT model\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_classifier = BERTClassifier(bert_model)\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load('/content/drive/MyDrive/D3/bert_model.pth')\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "bert_classifier.load_state_dict(state_dict)\n",
        "bert_classifier.eval()\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define prediction function with batching\n",
        "def predict_bert(texts, batch_size=16):\n",
        "    predictions = []\n",
        "    num_batches = int(np.ceil(len(texts) / batch_size))\n",
        "    for i in range(num_batches):\n",
        "        batch_texts = texts[i*batch_size:(i+1)*batch_size]\n",
        "        batch_texts = batch_texts.tolist()\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_classifier(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "        logits = outputs\n",
        "        batch_predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        predictions.extend(batch_predictions)\n",
        "        clear_memory()  # Clear memory after each batch\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Define Naive Bayes prediction function\n",
        "def predict_naive_bayes(texts):\n",
        "    return nb_pipeline.predict(texts)\n",
        "\n",
        "# Process in subsets to manage memory\n",
        "def process_in_subsets(X_test, y_test, subset_size=100):\n",
        "    combined_predictions = []\n",
        "    for i in range(0, len(X_test), subset_size):\n",
        "        X_subset = X_test[i:i+subset_size]\n",
        "        y_subset = y_test[i:i+subset_size]\n",
        "\n",
        "        # Get predictions from both models\n",
        "        bert_predictions = predict_bert(X_subset)\n",
        "        nb_predictions = predict_naive_bayes(X_subset)\n",
        "\n",
        "        # Combine predictions using majority voting\n",
        "        subset_combined_predictions = np.array([np.bincount([nb_pred, bert_pred]).argmax() for nb_pred, bert_pred in zip(nb_predictions, bert_predictions)])\n",
        "        combined_predictions.extend(subset_combined_predictions)\n",
        "\n",
        "        clear_memory()  # Clear memory after each subset\n",
        "\n",
        "    return np.array(combined_predictions)\n",
        "\n",
        "# Process the test set in subsets\n",
        "combined_predictions = process_in_subsets(X_test, y_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, combined_predictions)\n",
        "print(f\"Combined Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Print additional metrics\n",
        "print(\"Classification Report\")\n",
        "print(classification_report(y_test, combined_predictions))\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test, combined_predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NrokuuEudNPU",
        "1JOJ79g3dvHq",
        "_ihj8EU2rh3x",
        "If8P-enermPM",
        "yhacKJmmrsnj",
        "IOEA46W523ND"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003f8991096744bd9946ebce1ea3d91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "045de8e7f0054b238878cac135b1989f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0550d16471cd4783851b44e041cbcdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc5dd67b22d40c3aec85363377455fd",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9375c0c8b8a4481a4c156f076f5261b",
            "value": 570
          }
        },
        "056155d28f574b6a967a0970079bd4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13ae52e633694103876da0e2f74437af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_419f8140de0847a795964abb401aee63",
              "IPY_MODEL_9aaa2cc7c550454e9f0944bd6b445a60",
              "IPY_MODEL_5a6e0a8a21f7484e9841dd615dfcdf1c"
            ],
            "layout": "IPY_MODEL_bb734d0d7b864a7b8341cbf667119e2f"
          }
        },
        "1c4bec17d33f49d992307b972ad3cb28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2472382ab5ea49ad892ceb21830b71fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab261f382d64c8aa6e8ac940676373e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cc5dd67b22d40c3aec85363377455fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e256c93d9ee4df595bc2df1bff5798e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc570c9a0a34dc0a76abea559b511bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "419f8140de0847a795964abb401aee63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc570c9a0a34dc0a76abea559b511bf",
            "placeholder": "​",
            "style": "IPY_MODEL_adf6f98047004919aad42f804f22d24f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4c885e3bc2994fcfa1ab39bcca4e335c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b79740a45424f9086ef15b8a29055a3",
            "placeholder": "​",
            "style": "IPY_MODEL_cdd4936876a7457ca58306598604ce1b",
            "value": " 440M/440M [00:07&lt;00:00, 76.9MB/s]"
          }
        },
        "4ec0390564b348e7b0df83ba13fe0bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8aef8e1beaf46cfb201137e7450d3cc",
              "IPY_MODEL_8c5e7dc644344d9eb209ece03665d175",
              "IPY_MODEL_9df5993ed4924f1b97cea32fe12f54ce"
            ],
            "layout": "IPY_MODEL_c1b2856b14d84a028e766b96e4292275"
          }
        },
        "4f7afef1c86f4e6f91533ced83d16737": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54aa16bb9f0b44cab597a91ea087d4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59fb7ac14709495e86f29eede0dde3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a6e0a8a21f7484e9841dd615dfcdf1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abde59b07c8a47b7b4c50556f8440c55",
            "placeholder": "​",
            "style": "IPY_MODEL_838e080ea88445ccaa7c2dfa68e47b41",
            "value": " 48.0/48.0 [00:00&lt;00:00, 902B/s]"
          }
        },
        "5d98a015b12d4c79b09962ed30e7ec0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66eb07f83f1949aa860866da570835c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6851f1e0ca7b4cefb2c827ecd08f26a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_950a24ccbff0437492b48e5d653634cc",
              "IPY_MODEL_ef439366f90748d9b13294de11d1cc79",
              "IPY_MODEL_b398fcf807d443e2bc812900a46d4ad6"
            ],
            "layout": "IPY_MODEL_5d98a015b12d4c79b09962ed30e7ec0b"
          }
        },
        "6af2136c37ab4b4ca3b88f5985232299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1139ecfcd242159c43faa54da75447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c41b84d9f74f44abb558c22e37f59171",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a731d2f363454e8fe6c0b9f7420f87",
            "value": " 570/570 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "768cef91b36d43c7bbdd71c511a00a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a02b1c7410974b8f97cbf7732705e1ca",
              "IPY_MODEL_0550d16471cd4783851b44e041cbcdd6",
              "IPY_MODEL_6d1139ecfcd242159c43faa54da75447"
            ],
            "layout": "IPY_MODEL_a604b0300cd747438fac198673940b13"
          }
        },
        "7b79740a45424f9086ef15b8a29055a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9f96ab309d48ffbd0dbc4b36bbed3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82bb2d43371e4f35a168984c21b3d283",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ab261f382d64c8aa6e8ac940676373e",
            "value": 440449768
          }
        },
        "82bb2d43371e4f35a168984c21b3d283": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838e080ea88445ccaa7c2dfa68e47b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8af8e9eef5594a468eb77e37ddc8eae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c5e7dc644344d9eb209ece03665d175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fec4d8f088349d1832e34416209799b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8af8e9eef5594a468eb77e37ddc8eae7",
            "value": 231508
          }
        },
        "8d82ccf379604810957b35130a9ff0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "950a24ccbff0437492b48e5d653634cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa553849733d413d82aac85778459e29",
            "placeholder": "​",
            "style": "IPY_MODEL_8d82ccf379604810957b35130a9ff0e5",
            "value": "tokenizer.json: 100%"
          }
        },
        "98241dc3f5c842748ecc930a2c15e3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a174556292b4491798f11dc02f004961",
              "IPY_MODEL_7c9f96ab309d48ffbd0dbc4b36bbed3e",
              "IPY_MODEL_4c885e3bc2994fcfa1ab39bcca4e335c"
            ],
            "layout": "IPY_MODEL_045de8e7f0054b238878cac135b1989f"
          }
        },
        "98f25e63489e4d579de917f04fe48592": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aaa2cc7c550454e9f0944bd6b445a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2472382ab5ea49ad892ceb21830b71fc",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0ea6dea36874649a0bcd5bd46fa0751",
            "value": 48
          }
        },
        "9df5993ed4924f1b97cea32fe12f54ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4bec17d33f49d992307b972ad3cb28",
            "placeholder": "​",
            "style": "IPY_MODEL_fb18ba3dea24467fa21102d89efddc4b",
            "value": " 232k/232k [00:00&lt;00:00, 2.08MB/s]"
          }
        },
        "9fec4d8f088349d1832e34416209799b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02b1c7410974b8f97cbf7732705e1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59fb7ac14709495e86f29eede0dde3b7",
            "placeholder": "​",
            "style": "IPY_MODEL_003f8991096744bd9946ebce1ea3d91c",
            "value": "config.json: 100%"
          }
        },
        "a174556292b4491798f11dc02f004961": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66eb07f83f1949aa860866da570835c4",
            "placeholder": "​",
            "style": "IPY_MODEL_d859f836a3da436282e5524cf31b783a",
            "value": "model.safetensors: 100%"
          }
        },
        "a1a731d2f363454e8fe6c0b9f7420f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a604b0300cd747438fac198673940b13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9375c0c8b8a4481a4c156f076f5261b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa553849733d413d82aac85778459e29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abde59b07c8a47b7b4c50556f8440c55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf6f98047004919aad42f804f22d24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b398fcf807d443e2bc812900a46d4ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7afef1c86f4e6f91533ced83d16737",
            "placeholder": "​",
            "style": "IPY_MODEL_056155d28f574b6a967a0970079bd4c8",
            "value": " 466k/466k [00:00&lt;00:00, 4.32MB/s]"
          }
        },
        "bb734d0d7b864a7b8341cbf667119e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b2856b14d84a028e766b96e4292275": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41b84d9f74f44abb558c22e37f59171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd4936876a7457ca58306598604ce1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ea6dea36874649a0bcd5bd46fa0751": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d859f836a3da436282e5524cf31b783a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8aef8e1beaf46cfb201137e7450d3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98f25e63489e4d579de917f04fe48592",
            "placeholder": "​",
            "style": "IPY_MODEL_2e256c93d9ee4df595bc2df1bff5798e",
            "value": "vocab.txt: 100%"
          }
        },
        "ef439366f90748d9b13294de11d1cc79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af2136c37ab4b4ca3b88f5985232299",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54aa16bb9f0b44cab597a91ea087d4ab",
            "value": 466062
          }
        },
        "fb18ba3dea24467fa21102d89efddc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}