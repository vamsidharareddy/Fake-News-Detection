{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search CV"
      ],
      "metadata": {
        "id": "yyfZLNQmJRK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VICi4CjEJVN-",
        "outputId": "533c4cf4-31bc-4043-b035-89c0e898f622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data['statement']\n",
        "y = data['label'].astype(int)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Define the SVM model and a smaller parameter grid\n",
        "svm = SVC()\n",
        "param_grid = {\n",
        "    'C': [1, 10],\n",
        "    'gamma': [0.1, 0.01],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV with fewer folds\n",
        "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best model and evaluate it\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_tfidf)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjvM9Q9EJUVu",
        "outputId": "ccec92bb-cf6d-4b6d-ff73-3567810c4390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Best parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Best cross-validation score: 0.6343961352657005\n",
            "Accuracy: 62.44%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.38      0.48       584\n",
            "           1       0.62      0.83      0.71       710\n",
            "\n",
            "    accuracy                           0.62      1294\n",
            "   macro avg       0.63      0.60      0.59      1294\n",
            "weighted avg       0.63      0.62      0.60      1294\n",
            "\n",
            "Confusion Matrix:\n",
            "[[220 364]\n",
            " [122 588]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Save the best model\n",
        "model_path = '/content/drive/MyDrive/D2/D2_svm/hyper.pkl'\n",
        "joblib.dump(best_model, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB80l8QtJcKQ",
        "outputId": "2dbda19c-2f8b-4380-97f7-2d7b0f18e8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/D2/D2_svm/hyper.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes"
      ],
      "metadata": {
        "id": "SetZzGxOJc8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIUeEHtbJjc-",
        "outputId": "892eafad-d528-42d9-baf8-562a2fc1118f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/107.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import joblib\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Define the SVM model with a pipeline (optional: include scaling)\n",
        "model = make_pipeline(StandardScaler(with_mean=False), SVC())  # Set with_mean=False\n",
        "\n",
        "# Define parameter ranges for Bayesian optimization\n",
        "param_space = {\n",
        "    'svc__C': (1e-6, 100.0, 'log-uniform'),\n",
        "    'svc__gamma': (1e-6, 100.0, 'log-uniform'),\n",
        "    'svc__kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "# Perform Bayesian optimization\n",
        "opt = BayesSearchCV(\n",
        "    model,\n",
        "    param_space,\n",
        "    n_iter=5,  # Adjust the number of iterations as needed\n",
        "    cv=5,  # Cross-validation folds\n",
        "    n_jobs=-1,  # Use all available cores\n",
        "    verbose=1  # Print optimization progress\n",
        ")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data['statement'])\n",
        "\n",
        "# Fit the optimizer on the transformed training data\n",
        "opt.fit(train_features, train_data['label'])\n",
        "# --- END_SOLUTION\n",
        "\n",
        "# Save the best SVM model\n",
        "import joblib\n",
        "\n",
        "save_path = '/content/drive/MyDrive/D2/D2_svm/bayesiansvm.pkl'\n",
        "joblib.dump(opt.best_estimator_, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJzZ-PN7J4zi",
        "outputId": "7174e4b3-ca7d-45f3-ad55-694e984b1c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/D2/D2_svm/bayesiansvm.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "X_val = vectorizer.transform(val_data['statement'])\n",
        "y_val = val_data['label']\n",
        "y_val_pred = opt.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Preprocess the test data\n",
        "X_test = vectorizer.transform(test_data['statement'])\n",
        "y_test = test_data['label']\n",
        "y_test_pred = opt.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test Set Performance:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdvskGHTJ42Y",
        "outputId": "3c991e0a-6b99-45ff-fd14-f0ca2d66ccd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.51      0.56       720\n",
            "           1       0.64      0.74      0.69       868\n",
            "\n",
            "    accuracy                           0.63      1588\n",
            "   macro avg       0.63      0.62      0.62      1588\n",
            "weighted avg       0.63      0.63      0.63      1588\n",
            "\n",
            "Validation Accuracy: 0.6329\n",
            "Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.29      0.35       714\n",
            "           1       0.37      0.54      0.44       553\n",
            "\n",
            "    accuracy                           0.40      1267\n",
            "   macro avg       0.41      0.41      0.40      1267\n",
            "weighted avg       0.41      0.40      0.39      1267\n",
            "\n",
            "Test Accuracy: 0.3986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PBT"
      ],
      "metadata": {
        "id": "91XpL8NrJkMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load the datasets\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming your 'label' column needs encoding (if not binary already)\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['label'] = label_encoder.fit_transform(train_data['label'])\n",
        "val_data['label'] = label_encoder.transform(val_data['label'])\n",
        "test_data['label'] = label_encoder.transform(test_data['label'])\n",
        "\n",
        "# Step 2: Feature extraction (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_data['statement'])\n",
        "X_val_tfidf = vectorizer.transform(val_data['statement'])\n",
        "X_test_tfidf = vectorizer.transform(test_data['statement'])\n",
        "y_train = train_data['label']\n",
        "y_val = val_data['label']\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Step 3: Train the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 4: Save the trained model\n",
        "model_save_path = '/content/drive/MyDrive/D2/D2_svm/pbt_svm.pkl'\n",
        "joblib.dump(svm_model, model_save_path)\n",
        "print(f\"Model saved successfully at {model_save_path}\")\n",
        "\n",
        "# Step 5: Evaluate the model's accuracy on validation data\n",
        "val_predictions = svm_model.predict(X_val_tfidf)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Step 6: Evaluate the model's accuracy on test data\n",
        "test_predictions = svm_model.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIRlt1AVaqlt",
        "outputId": "54376cb4-6af0-4a8e-f0e4-d6f31c9eeb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at /content/drive/MyDrive/D2/D2_svm/pbt_svm.pkl\n",
            "Validation Accuracy: 0.6322\n",
            "Test Accuracy: 0.3938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic"
      ],
      "metadata": {
        "id": "96oB4GcbJomY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "htOdWww7JvQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the datasets\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming your 'label' column needs encoding (if not binary already)\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['label'] = label_encoder.fit_transform(train_data['label'])\n",
        "val_data['label'] = label_encoder.transform(val_data['label'])\n",
        "test_data['label'] = label_encoder.transform(test_data['label'])\n",
        "\n",
        "# Step 2: Feature extraction (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_data['statement'])\n",
        "X_val_tfidf = vectorizer.transform(val_data['statement'])\n",
        "X_test_tfidf = vectorizer.transform(test_data['statement'])\n",
        "y_train = train_data['label']\n",
        "y_val = val_data['label']\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Genetic Algorithm Settings\n",
        "population_size = 10\n",
        "num_generations = 5\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# Genetic Algorithm Framework\n",
        "population = []\n",
        "for _ in range(population_size):\n",
        "    # Randomly initialize SVM hyperparameters\n",
        "    C = np.random.uniform(0.1, 10.0)\n",
        "    kernel = np.random.choice(['linear', 'rbf'])\n",
        "    gamma = 'scale' if kernel == 'rbf' else 'auto'\n",
        "\n",
        "    # Train SVM with current hyperparameters\n",
        "    svm_model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)\n",
        "    svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Evaluate fitness on validation set\n",
        "    val_predictions = svm_model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "    # Store hyperparameters and accuracy in population\n",
        "    population.append((svm_model, {'kernel': kernel, 'C': C, 'gamma': gamma}, accuracy))"
      ],
      "metadata": {
        "id": "lrxqwDzmKYpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolution loop\n",
        "for generation in range(num_generations):\n",
        "    # Sort population by fitness (accuracy)\n",
        "    population.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Print the best model in the current generation\n",
        "    best_model, best_hyperparams, best_accuracy = population[0]\n",
        "    print(f\"Generation {generation + 1}: Best Accuracy = {best_accuracy:.4f}, Hyperparameters = {best_hyperparams}\")\n",
        "\n",
        "    # Select top performers to produce offspring\n",
        "    selected_parents = population[:population_size // 2]\n",
        "\n",
        "    # Crossover and mutation\n",
        "    offspring_population = []\n",
        "    for i in range(population_size):\n",
        "        parent1, params1, _ = selected_parents[np.random.randint(len(selected_parents))]\n",
        "        parent2, params2, _ = selected_parents[np.random.randint(len(selected_parents))]\n",
        "\n",
        "        # Perform crossover (combine hyperparameters)\n",
        "        child_params = {}\n",
        "        for param_key in params1.keys():\n",
        "            if np.random.rand() < 0.5:\n",
        "                child_params[param_key] = params1[param_key]\n",
        "            else:\n",
        "                child_params[param_key] = params2[param_key]\n",
        "\n",
        "        # Perform mutation (slight modification to hyperparameters)\n",
        "        for param_key in child_params.keys():\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                if param_key == 'C':\n",
        "                    child_params[param_key] = np.random.uniform(0.1, 10.0)\n",
        "                elif param_key == 'kernel':\n",
        "                    child_params[param_key] = np.random.choice(['linear', 'rbf'])\n",
        "                    if child_params[param_key] == 'rbf':\n",
        "                        child_params['gamma'] = 'scale'  # Adjust gamma for RBF kernel\n",
        "\n",
        "        # Train SVM with mutated hyperparameters\n",
        "        child_model = SVC(kernel=child_params['kernel'], C=child_params['C'], gamma=child_params['gamma'], random_state=42)\n",
        "        child_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        # Evaluate fitness on validation set\n",
        "        val_predictions = child_model.predict(X_val_tfidf)\n",
        "        accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "        # Add child to offspring population\n",
        "        offspring_population.append((child_model, child_params, accuracy))\n",
        "\n",
        "    # Replace the old population with the offspring\n",
        "    population = offspring_population"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Y5Rdt7KiG8",
        "outputId": "e61ec913-24b2-45d6-a6f0-29b904452551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best Accuracy = 0.6549, Hyperparameters = {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n",
            "Generation 2: Best Accuracy = 0.6549, Hyperparameters = {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n",
            "Generation 3: Best Accuracy = 0.6549, Hyperparameters = {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n",
            "Generation 4: Best Accuracy = 0.6549, Hyperparameters = {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n",
            "Generation 5: Best Accuracy = 0.6549, Hyperparameters = {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final best model evaluation on test set\n",
        "population.sort(key=lambda x: x[2], reverse=True)\n",
        "best_model, best_hyperparams, best_accuracy = population[0]\n",
        "print(f\"Best Model - Accuracy on Validation Set: {best_accuracy:.4f}, Hyperparameters: {best_hyperparams}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_predictions = best_model.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Accuracy on Test Set: {test_accuracy:.4f}\")\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Final best model evaluation on test set\n",
        "population.sort(key=lambda x: x[2], reverse=True)\n",
        "best_model, best_hyperparams, best_accuracy = population[0]\n",
        "print(f\"Best Model - Accuracy on Validation Set: {best_accuracy:.4f}, Hyperparameters: {best_hyperparams}\")\n",
        "\n",
        "# Save the best model\n",
        "model_save_path = '/content/drive/MyDrive/D2/D2_svm/geneticsvm.pkl'\n",
        "joblib.dump(best_model, model_save_path)\n",
        "print(f\"Saved the best SVM model to {model_save_path}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_predictions = best_model.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Accuracy on Test Set: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4aHLlhhKYsd",
        "outputId": "a138e0db-1599-4d56-e22d-99fb98645879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model - Accuracy on Validation Set: 0.6549, Hyperparameters: {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n",
            "Accuracy on Test Set: 0.3828\n",
            "Best Model - Accuracy on Validation Set: 0.6549, Hyperparameters: {'kernel': 'rbf', 'C': 0.4553378068753463, 'gamma': 'scale'}\n",
            "Saved the best SVM model to /content/drive/MyDrive/D2/D2_svm/geneticsvm.pkl\n",
            "Accuracy on Test Set: 0.3828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperband"
      ],
      "metadata": {
        "id": "HpnPYLC7Jv21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FM3f7xpJzKJ",
        "outputId": "bc269540-18a4-4db8-8d29-c7236b4f2dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.callbacks import VerboseCallback\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "# ... (Your previous code) ...\n",
        "# Convert 'label' column to string type before using .str accessor\n",
        "train_data['label'] = train_data['label'].astype(str).str.lower().apply(lambda x: 1 if x == 'false' else 0)\n",
        "val_data['label'] = val_data['label'].astype(str).str.lower().apply(lambda x: 1 if x == 'false' else 0)\n",
        "test_data['label'] = test_data['label'].astype(str).str.lower().apply(lambda x: 1 if x == 'false' else 0)\n",
        "\n",
        "# --- Check label distribution AFTER conversion ---\n",
        "print(\"Train data labels after conversion:\", train_data['label'].value_counts())\n",
        "print(\"Validation data labels after conversion:\", val_data['label'].value_counts())\n",
        "# ... rest of your code\n",
        "# Combine train and val data for hyperparameter tuning\n",
        "X_train = train_data['statement']\n",
        "y_train = train_data['label']\n",
        "X_val = val_data['statement']\n",
        "y_val = val_data['label']\n",
        "\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Define the parameter space for Hyperband\n",
        "param_space = {\n",
        "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "    'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "    'degree': Integer(1, 8),  # Only used for 'poly' kernel\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXLZedgYKovF",
        "outputId": "132fb293-0b31-46cd-a8d0-0a72944d4885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data labels after conversion: label\n",
            "0    6469\n",
            "Name: count, dtype: int64\n",
            "Validation data labels after conversion: label\n",
            "0    1588\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique labels in training data\n",
        "print(y_train.unique())\n",
        "\n",
        "# Check distribution of labels\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jBR6lHBKoxf",
        "outputId": "09b8b258-90d7-4f5f-c87e-47cf51f23a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "label\n",
            "0    6469\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if you have more than one class in your training data\n",
        "if len(train_data['label'].unique()) <= 1:\n",
        "    print(\"WARNING: Your training data only has one class. This will cause errors with SVM.\")\n",
        "else:\n",
        "    print(\"You have multiple classes in your training data, you should be good to go!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ChTMFaCbL-C",
        "outputId": "3e15ac60-11ed-4e58-d557-ff11bd0ab8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have multiple classes in your training data, you should be good to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.head())\n",
        "print(val_data.head())\n",
        "print(train_data['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mwP88b6bOmb",
        "outputId": "c9398612-72ce-4fe7-c4df-0e39eafc8a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                          statement\n",
            "0      1  I investigated Abramoff and people ended up in...\n",
            "1      0  Takes credit for reining in state spending whe...\n",
            "2      0  Most of your serial killers, most of your peop...\n",
            "3      0  Says Hillary Clinton wants to essentially abol...\n",
            "4      0  The first round of stimulus ... it created zer...\n",
            "   label                                          statement\n",
            "0      1  It costs $10,000 a year to keep a child in sch...\n",
            "1      0                                    On Common Core.\n",
            "2      1  This March, for the first time in human histor...\n",
            "3      1  Quite frankly, it was during the Bush years of...\n",
            "4      1  Cap and trade legislation was originally a Rep...\n",
            "label\n",
            "1    3636\n",
            "0    2833\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SVM model\n",
        "svc = SVC()\n",
        "\n",
        "# Stratified K-Fold for better class distribution in splits\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform Hyperband search with StratifiedKFold\n",
        "hyperband = BayesSearchCV(svc, param_space, n_iter=5, cv=skf, n_jobs=-1, random_state=42, scoring='accuracy')\n",
        "hyperband.fit(X_train_tfidf, y_train, callback=VerboseCallback(n_total=20))\n",
        "\n",
        "# Print the best parameters found\n",
        "print(f\"Best parameters found: {hyperband.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOLXFRA8K3Vf",
        "outputId": "e1b34bf0-c879-4963-eb53-7b48c0d06339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Searching for the next optimal point.\n",
            "Iteration No: 1 ended. Search finished for the next optimal point.\n",
            "Time taken: 17.9894\n",
            "Function value obtained: -0.5814\n",
            "Current minimum: -0.5814\n",
            "Iteration No: 2 started. Searching for the next optimal point.\n",
            "Iteration No: 2 ended. Search finished for the next optimal point.\n",
            "Time taken: 10.9298\n",
            "Function value obtained: -0.6231\n",
            "Current minimum: -0.6231\n",
            "Iteration No: 3 started. Searching for the next optimal point.\n",
            "Iteration No: 3 ended. Search finished for the next optimal point.\n",
            "Time taken: 8.4368\n",
            "Function value obtained: -0.5621\n",
            "Current minimum: -0.6231\n",
            "Iteration No: 4 started. Searching for the next optimal point.\n",
            "Iteration No: 4 ended. Search finished for the next optimal point.\n",
            "Time taken: 110.0773\n",
            "Function value obtained: -0.6043\n",
            "Current minimum: -0.6231\n",
            "Iteration No: 5 started. Searching for the next optimal point.\n",
            "Iteration No: 5 ended. Search finished for the next optimal point.\n",
            "Time taken: 25.5874\n",
            "Function value obtained: -0.6063\n",
            "Current minimum: -0.6231\n",
            "Iteration No: 6 started. Searching for the next optimal point.\n",
            "Best parameters found: OrderedDict([('C', 11185.625288472094), ('degree', 7), ('gamma', 0.00013300585802877296), ('kernel', 'sigmoid')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "best_model = hyperband.best_estimator_\n",
        "model_path = '/content/drive/MyDrive/D2/D2_svm/hyperbandsvm.pkl'\n",
        "joblib.dump(best_model, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub06hf9HK3Tk",
        "outputId": "1d94bc87-dde7-47bd-a702-43edfa59fc79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/D2/D2_svm/hyperbandsvm.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "y_val_pred = best_model.predict(X_val_tfidf)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# Preprocess the test data\n",
        "X_test = test_data['statement']\n",
        "y_test = test_data['label']\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_test_pred = best_model.predict(X_test_tfidf)\n",
        "print(\"Test Set Performance:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfekoMUbK9rU",
        "outputId": "66936024-a258-4bb2-d3d5-dd4b490a3cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.53      0.56       720\n",
            "           1       0.65      0.71      0.68       868\n",
            "\n",
            "    accuracy                           0.63      1588\n",
            "   macro avg       0.62      0.62      0.62      1588\n",
            "weighted avg       0.63      0.63      0.63      1588\n",
            "\n",
            "Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.31      0.37       714\n",
            "           1       0.36      0.50      0.42       553\n",
            "\n",
            "    accuracy                           0.40      1267\n",
            "   macro avg       0.40      0.41      0.39      1267\n",
            "weighted avg       0.41      0.40      0.39      1267\n",
            "\n"
          ]
        }
      ]
    }
  ]
}