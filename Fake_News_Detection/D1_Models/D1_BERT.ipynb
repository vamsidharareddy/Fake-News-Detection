{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb9qKvDdMbNX"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYNPBqRnEdJT",
    "outputId": "8441489d-dce7-40d9-fc3f-707b9f4d41ae"
   },
   "outputs": [],
   "source": [
    "# Install specific libraries\n",
    "! pip install transformers\n",
    "! pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z87VIUd764p",
    "outputId": "b5436141-b993-4d83-8d94-d8fa499029b9"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HKsESMV8S-q",
    "outputId": "d5799d14-7cc2-46ad-9f82-49ac53089cb5"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIFgZcfWlC8F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycaret\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiX5DhZE-vzP",
    "outputId": "e2f0be22-0009-48b4-915b-887c355cc779"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive - applicable, if working on Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xkkoUVsEu_w",
    "outputId": "3d088577-662d-4b16-b6d2-3e4a870394f9"
   },
   "outputs": [],
   "source": [
    "# Set Working Directory - if working on Google Drive\n",
    "%cd /content/drive/MyDrive/Project11_FakeNewsDetection\n",
    "\n",
    "# # Set Working Directory - if working on Local Machine\n",
    "# import os\n",
    "# os.chdir('/Users//replace_me')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar3qNZz0MiGk"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "9Gkv1hk-mr9Z",
    "outputId": "c264fee9-4fcf-4629-b65e-5c6d5c9e9434"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "true_data = pd.read_csv('a1_True.csv')\n",
    "fake_data = pd.read_csv('a2_Fake.csv')\n",
    "\n",
    "# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n",
    "true_data['Target'] = 'True'\n",
    "fake_data['Target'] = 'Fake'\n",
    "\n",
    "# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n",
    "data = pd.concat([true_data, fake_data]).sample(frac=1).reset_index().drop(columns=['index'])\n",
    "\n",
    "# See how the data looks like\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u86aL9M0WA3T"
   },
   "outputs": [],
   "source": [
    "# Target column is made of string values True/Fake, let's change it to numbers 0/1 (Fake=1)\n",
    "data['label'] = pd.get_dummies(data.Target)['Fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "yt2qbRKOwz-H",
    "outputId": "85f132c3-1968-49c7-dd90-2c9427056d94"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "6GR5qqqwoVAc",
    "outputId": "86d7aab9-3817-456b-df34-0c95d6eb9a8d"
   },
   "outputs": [],
   "source": [
    "# Checking if our data is well balanced\n",
    "label_size = [data['label'].sum(),len(data['label'])-data['label'].sum()]\n",
    "plt.pie(label_size,explode=[0.1,0.1],colors=['firebrick','navy'],startangle=90,shadow=True,labels=['Fake','True'],autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj5h7QbnZC0t"
   },
   "source": [
    "## Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P9DYEq3y6pR"
   },
   "outputs": [],
   "source": [
    "# Train-Validation-Test set split into 70:15:15 ratio\n",
    "# Train-Temp split\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(data['title'], data['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=data['Target'])\n",
    "# Validation-Test split\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ItKm0hDMujq"
   },
   "source": [
    "## BERT Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIkcURDhz2R0"
   },
   "source": [
    "### Load pretrained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "67eac869bd3d4900a4c727ecc2ff2b40",
      "c686b67b6b2641c182d4d83b8f6c5166",
      "9c08a2ba28244c1a8d8707de5c0e86c7",
      "1b5931713a9c4f538a2520f6ab2870b6",
      "e4996cc2b72f4a10a12fe6c68549b5ae",
      "26d397d831e443e49c8d0210d082a872",
      "4fb7c223713f44cb87a36ba7a086cf43",
      "71c292121be3480591c1fc8e79331aba",
      "64bfacc65e0e45629c5086b03027e8d6",
      "a20a073132fd4cc8a01b21553fb9aa76",
      "bf595f72c0b943b0ae8a0a7f1b777d88",
      "eb4997d9e32240c3b2d65268c06a1570",
      "e03a712bd0d5472db8b023bd7b2f5a61",
      "9319116705be4dbb9a5892134bc6942a",
      "87d6dccb51ac4d8093b976849d5662a3",
      "17d0c41df95246b5ad1e7fae74c6a655",
      "ec45badd3b11427f9d4b09ec4329300f",
      "423788e1720149cb92c60ccd61557bef",
      "00b71de03f394bce8e26aca0bc039fce",
      "b199e5753c2344a48246d195a0107b63",
      "4a4bf3ae22bc4b35b3bf7a733e34654e",
      "bd403ae42dbc40a3a406539fe168f278",
      "f5f45d1ca82b45dd9d61d9b6d8398d43",
      "1e68a6d6c1594de698c67bebc5fc23e9",
      "d9a9159f5fc24e4f94a8cea2203f21d6",
      "3be6b9cae1d94e039313b8bac77fa1a7",
      "49a98967c1b04064a933bbf66f946281",
      "e2cf993269d34a5fa7c066f9fd54b2da",
      "2b3ae4df3a7e4689aa4bd6910b8d0ff5",
      "13db723e63a2436f99b0a5cfba38c21a",
      "9057c0d2cbf94328aa27dca52285beb4",
      "942137c329824fc28a38a31d0303c6e0",
      "9a2b81dba4ba4753836fc9cf54595de1",
      "3ef7c3f322f44340945cea9c4f9759e5",
      "01105dc7948e4d1da175ad5a72f67be3",
      "f165a6209a6c4009b71914404abbb46c",
      "cedbfb33c01d4600837ee1335372afd4",
      "7f1b6de7125340f796d295a204cabfb0",
      "a641a87c82ab487eaa8b5fbaa25086c4",
      "ff797e3b2ea3468e8dea8e1de0332447",
      "45ce25fdc623489c9bf475ec242de7b7",
      "ef303360020b4248ba7a5787d06d66d3",
      "2699fa609bd8489eba4e2cb4bcb9b15e",
      "9a8bad0c752246dc9e640dcc3d4a16dd",
      "feb70516cd204bafa3e631cbca6fb717",
      "fa2cc9cecff8401ba42db041f275970f",
      "5e18e2682f044ee5b5d56e2fd004aa80",
      "268307f55e24412d8ef78c689dd2e87e",
      "538765f161f143f0ad7cd6e9172af578",
      "6b934af7736942c6bf4d7ca6f4213a08",
      "8e76d567611041d7a4c1c735d89d79f4",
      "06e168be066246d58f5d5273df615830",
      "697306d0a6c040f49562331b8c0d10f8",
      "aa723e6b0f1c41d0ba78ae1da8817721",
      "e86fece3830248f1a8b2e4ebc31e76a8"
     ]
    },
    "id": "w6skrhdVzW0b",
    "outputId": "776da4b5-abd3-48a9-8e8d-4697e50f7dfb"
   },
   "outputs": [],
   "source": [
    "# Load BERT model and tokenizer via HuggingFace Transformers\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1G4xtl7dXBD"
   },
   "source": [
    "### Prepare Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "FDZx-O2xzcA_",
    "outputId": "649cecbf-fb04-4bc4-d04e-7a2c432add16"
   },
   "outputs": [],
   "source": [
    "# Plot histogram of the number of words in train data 'title'\n",
    "seq_len = [len(title.split()) for title in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 40,color='firebrick')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Number of texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ry0ptLTW-Chy",
    "outputId": "38cf30c3-1bed-4bbe-e0d9-33302eb3cee3"
   },
   "outputs": [],
   "source": [
    "# BERT Tokeizer Functionality\n",
    "sample_data = [\"Build fake news model.\",\n",
    "               \"Using bert.\"]                                         # sample data\n",
    "tokenized_sample_data = tokenizer.batch_encode_plus(sample_data,\n",
    "                                                    padding=True)     # encode text\n",
    "print(tokenized_sample_data)\n",
    "\n",
    "# Ref: https://huggingface.co/docs/transformers/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfwINnZozkyd"
   },
   "outputs": [],
   "source": [
    "# Majority of titles above have word length under 15. So, we set max title length as 15\n",
    "MAX_LENGHT = 15\n",
    "# Tokenize and encode sequences in the train set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jE9PI9_H0Moi"
   },
   "outputs": [],
   "source": [
    "# Convert lists to tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oft-16jR0M6h"
   },
   "outputs": [],
   "source": [
    "# Data Loader structure definition\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32                                               #define a batch size\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)    # wrap tensors\n",
    "train_sampler = RandomSampler(train_data)                     # sampler for sampling the data during training\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for train set\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)            # wrap tensors\n",
    "val_sampler = SequentialSampler(val_data)                     # sampler for sampling the data during training\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
    "                                                              # dataLoader for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkHiWeqop3Q_"
   },
   "source": [
    "### Freeze Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dH-wI1yhzQkD"
   },
   "outputs": [],
   "source": [
    "# Freezing the parameters and defining trainable BERT structure\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False    # false here means gradient need not be computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAJPyGH4zaRZ"
   },
   "source": [
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oC6f5jD0vm0"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "      super(BERT_Arch, self).__init__()\n",
    "      self.bert = bert\n",
    "      self.dropout = nn.Dropout(0.1)            # dropout layer\n",
    "      self.relu =  nn.ReLU()                    # relu activation function\n",
    "      self.fc1 = nn.Linear(768,512)             # dense layer 1\n",
    "      self.fc2 = nn.Linear(512,2)               # dense layer 2 (Output layer)\n",
    "      self.softmax = nn.LogSoftmax(dim=1)       # softmax activation function\n",
    "    def forward(self, sent_id, mask):           # define the forward pass\n",
    "      cls_hs = self.bert(sent_id, attention_mask=mask)['pooler_output']\n",
    "                                                # pass the inputs to the model\n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      x = self.fc2(x)                           # output layer\n",
    "      x = self.softmax(x)                       # apply softmax activation\n",
    "      return x\n",
    "\n",
    "model = BERT_Arch(bert)\n",
    "# Defining the hyperparameters (optimizer, weights of the classes and the epochs)\n",
    "# Define the optimizer\n",
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)          # learning rate\n",
    "# Define the loss function\n",
    "cross_entropy  = nn.NLLLoss()\n",
    "# Number of training epochs\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGFpP494zgLh"
   },
   "source": [
    "### Define Train & Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEG81NvL1Rt9"
   },
   "outputs": [],
   "source": [
    "# Defining training and evaluation functions\n",
    "def train():\n",
    "  model.train()\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "\n",
    "  for step,batch in enumerate(train_dataloader):                # iterate over batches\n",
    "    if step % 50 == 0 and not step == 0:                        # progress update after every 50 batches.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "    batch = [r for r in batch]                                  # push the batch to gpu\n",
    "    sent_id, mask, labels = batch\n",
    "    model.zero_grad()                                           # clear previously calculated gradients\n",
    "    preds = model(sent_id, mask)                                # get model predictions for current batch\n",
    "    loss = cross_entropy(preds, labels)                         # compute loss between actual & predicted values\n",
    "    total_loss = total_loss + loss.item()                       # add on to the total loss\n",
    "    loss.backward()                                             # backward pass to calculate the gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n",
    "    optimizer.step()                                            # update parameters\n",
    "    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n",
    "\n",
    "  avg_loss = total_loss / len(train_dataloader)                 # compute training loss of the epoch\n",
    "                                                                # reshape predictions in form of (# samples, # classes)\n",
    "  return avg_loss                                 # returns the loss and predictions\n",
    "\n",
    "def evaluate():\n",
    "  print(\"\\nEvaluating...\")\n",
    "  model.eval()                                    # Deactivate dropout layers\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  for step,batch in enumerate(val_dataloader):    # Iterate over batches\n",
    "    if step % 50 == 0 and not step == 0:          # Progress update every 50 batches.\n",
    "                                                  # Calculate elapsed time in minutes.\n",
    "                                                  # Elapsed = format_time(time.time() - t0)\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "                                                  # Report progress\n",
    "    batch = [t for t in batch]                    # Push the batch to GPU\n",
    "    sent_id, mask, labels = batch\n",
    "    with torch.no_grad():                         # Deactivate autograd\n",
    "      preds = model(sent_id, mask)                # Model predictions\n",
    "      loss = cross_entropy(preds,labels)          # Compute the validation loss between actual and predicted values\n",
    "      total_loss = total_loss + loss.item()\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "  avg_loss = total_loss / len(val_dataloader)         # compute the validation loss of the epoch\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfWaZg6wWGA_"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  model.train()\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "\n",
    "  for step,batch in enumerate(train_dataloader):                # iterate over batches\n",
    "    if step % 50 == 0 and not step == 0:                        # progress update after every 50 batches.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "    batch = [r for r in batch]                                  # push the batch to gpu\n",
    "    sent_id, mask, labels = batch\n",
    "    model.zero_grad()                                           # clear previously calculated gradients\n",
    "    preds = model(sent_id, mask)                                # get model predictions for current batch\n",
    "    loss = cross_entropy(preds, labels.long())                         # compute loss between actual & predicted values\n",
    "    total_loss = total_loss + loss.item()                       # add on to the total loss\n",
    "    loss.backward()                                             # backward pass to calculate the gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)     # clip gradients to 1.0. It helps in preventing exploding gradient problem\n",
    "    optimizer.step()                                            # update parameters\n",
    "    preds=preds.detach().cpu().numpy()                          # model predictions are stored on GPU. So, push it to CPU\n",
    "\n",
    "  avg_loss = total_loss / len(val_dataloader)                 # compute training loss of the epoch\n",
    "                                                                # reshape predictions in form of (# samples, # classes)\n",
    "  return avg_loss                                 # returns the loss and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3ompV-VX7Cl"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        sent_id, mask, labels = [r.to(device) for r in batch]  # Push the batch to the device (CPU or GPU)\n",
    "        labels = labels.long()  # Convert labels to Long data type\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "        sent_id, mask, labels = [t.to(device) for t in batch]\n",
    "        labels = labels.long()  # Convert labels to Long data type\n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiYIMAArkaZf",
    "outputId": "062077d1-e0ee-45d4-a279-5369ded6016d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uKfCQ9Bktto",
    "outputId": "5f4e3d9b-a94d-4843-8202-ab065394180a"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bjAdquok8b3"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # Move batch to CPU\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels.long())\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IARpecoUzloO"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSN0ZPiW1d-e",
    "outputId": "7766ed04-a6de-42fb-f701-ba6dde8e64db"
   },
   "outputs": [],
   "source": [
    "# Train and predict\n",
    "best_valid_loss = float('inf')\n",
    "train_losses=[]                   # empty lists to store training and validation loss of each epoch\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    train_loss = train()                       # train model\n",
    "    valid_loss = evaluate()                    # evaluate model\n",
    "    if valid_loss < best_valid_loss:              # save the best model\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'c2_new_model_weights.pt')\n",
    "    train_losses.append(train_loss)               # append training and validation loss\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp7jw9a6qiPt"
   },
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fVcPQH5oTc6"
   },
   "outputs": [],
   "source": [
    "# load weights of best model\n",
    "#path = 'c1_fakenews_weights.pt'\n",
    "#model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e64qJ5mCSyZn",
    "outputId": "5f99a6fb-e01d-4986-a6d8-89aac1c9c913"
   },
   "outputs": [],
   "source": [
    "# load weights of best model\n",
    "path = 'c1_fakenews_weights.pt'\n",
    "state_dict = torch.load(path)\n",
    "for key in list(state_dict.keys()):\n",
    "    if 'position_ids' in key:\n",
    "        del state_dict[key]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRgRYquAoWbu",
    "outputId": "4a01c0b7-29b2-4463-e3e8-43cc07a58f93"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  preds = model(test_seq, test_mask)\n",
    "  preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0epiFxHj_J9",
    "outputId": "dca79034-fb3b-41a4-db28-bfe80865c534"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming y_val and y_pred are your true labels and predicted labels, respectively\n",
    "y_true = y_val  # Ground truth labels from validation set\n",
    "y_pred = svm_model.predict(X_val_tfidf)  # Predicted labels from SVM model\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate True Positives, False Positives, False Negatives for each class\n",
    "true_positives = np.diag(conf_matrix)\n",
    "false_positives = np.sum(conf_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(conf_matrix, axis=1) - true_positives\n",
    "\n",
    "# Calculate Precision, Recall, F1-score for each class\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate macro-averaged precision, recall, F1-score\n",
    "macro_precision = np.mean(precision)\n",
    "macro_recall = np.mean(recall)\n",
    "macro_f1_score = np.mean(f1_score)\n",
    "\n",
    "# Calculate weighted-averaged precision, recall, F1-score\n",
    "weighted_precision = np.sum(precision * (true_positives + false_positives)) / np.sum(true_positives + false_positives)\n",
    "weighted_recall = np.sum(recall * (true_positives + false_negatives)) / np.sum(true_positives + false_negatives)\n",
    "weighted_f1_score = np.sum(f1_score * (true_positives + false_negatives)) / np.sum(true_positives + false_negatives)\n",
    "\n",
    "# Print results\n",
    "print(\"Precision, Recall, F1-score for each class:\")\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.3f}\")\n",
    "    print(f\"  Recall: {recall[i]:.3f}\")\n",
    "    print(f\"  F1-score: {f1_score[i]:.3f}\")\n",
    "\n",
    "print(\"\\nMacro-averaged metrics:\")\n",
    "print(f\"Macro-averaged Precision: {macro_precision:.3f}\")\n",
    "print(f\"Macro-averaged Recall: {macro_recall:.3f}\")\n",
    "print(f\"Macro-averaged F1-score: {macro_f1_score:.3f}\")\n",
    "\n",
    "print(\"\\nWeighted-averaged metrics:\")\n",
    "print(f\"Weighted-averaged Precision: {weighted_precision:.3fs}\")\n",
    "print(f\"Weighted-averaged Recall: {weighted_recall:.3f}\")\n",
    "print(f\"Weighted-averaged F1-score: {weighted_f1_score:.3f}\")\n",
    "\n",
    "# Additional metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "CFVwN4xjlimx",
    "outputId": "cbf7366a-b49c-4ea8-d802-983e53ec150a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert predictions to numpy array if not already\n",
    "preds = preds.cpu().numpy() if isinstance(preds, torch.Tensor) else preds\n",
    "\n",
    "# Convert test_y to numpy array if not already\n",
    "test_y = test_y.cpu().numpy() if isinstance(test_y, torch.Tensor) else test_y\n",
    "\n",
    "# Calculate True Positives, False Positives, False Negatives for each class\n",
    "conf_matrix = np.zeros((2, 2), dtype=np.int64)\n",
    "for true_label, pred_label in zip(test_y, preds):\n",
    "    conf_matrix[true_label, pred_label] += 1\n",
    "\n",
    "true_positives = np.diag(conf_matrix)\n",
    "false_positives = np.sum(conf_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(conf_matrix, axis=1) - true_positives\n",
    "\n",
    "# Calculate Precision, Recall, F1-score for each class\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate macro-averaged precision, recall, F1-score\n",
    "macro_precision = np.mean(precision)\n",
    "macro_recall = np.mean(recall)\n",
    "macro_f1_score = np.mean(f1_score)\n",
    "\n",
    "# Calculate weighted-averaged precision, recall, F1-score\n",
    "weighted_precision = np.sum(precision * (true_positives + false_positives)) / np.sum(true_positives + false_positives)\n",
    "weighted_recall = np.sum(recall * (true_positives + false_negatives)) / np.sum(true_positives + false_negatives)\n",
    "weighted_f1_score = np.sum(f1_score * (true_positives + false_negatives)) / np.sum(true_positives + false_negatives)\n",
    "\n",
    "# Print results\n",
    "print(\"Precision, Recall, F1-score for each class:\")\n",
    "for i in range(2):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.3f}\")\n",
    "    print(f\"  Recall: {recall[i]:.3f}\")\n",
    "    print(f\"  F1-score: {f1_score[i]:.3f}\")\n",
    "\n",
    "print(\"\\nMacro-averaged metrics:\")\n",
    "print(f\"Macro-averaged Precision: {macro_precision:.3f}\")\n",
    "print(f\"Macro-averaged Recall: {macro_recall:.3f}\")\n",
    "print(f\"Macro-averaged F1-score: {macro_f1_score:.3f}\")\n",
    "\n",
    "print(\"\\nWeighted-averaged metrics:\")\n",
    "print(f\"Weighted-averaged Precision: {weighted_precision:.3f}\")\n",
    "print(f\"Weighted-averaged Recall: {weighted_recall:.3f}\")\n",
    "print(f\"Weighted-averaged F1-score: {weighted_f1_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P95XPCMoq8nN"
   },
   "source": [
    "## Fake News Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVr9XJT14dO2"
   },
   "outputs": [],
   "source": [
    "# # load weights of best model\n",
    "# path = 'c1_fakenews_weights.pt'\n",
    "# model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbxvA9qNe2LP",
    "outputId": "b531db97-da51-496f-8fdf-61c597a3424b"
   },
   "outputs": [],
   "source": [
    "unseen_news_text = [r\"President Trump slammed Nancy Pelosi Tuesday, calling her a 'sick woman' with a lot of 'mental problems' after Pelosi said Trump should fear for his life taking hydroxychloroquine because he is 'morbidly obese'. Trump also hit out at a study on hydroxychloroquine, claiming it can have severe side effects leading to death, calling the results a 'Trump enemy statement.'\",\n",
    "                    \"I’ve worked with doctors and if you look at the one survey – the only bad survey – they were giving it to people that were in very bad shape. They were very old, almost dead. the President asserted.\",\n",
    "                    \"Trump again claimed that many front line healthcare workers are taking hydroxychloroquine. 'A lot of our front line workers take it because it possibly and – I think it does but you know these people are going to have to make up their own mind. Plus, it doesn’t hurt people. It’s been out of the market for 60 or 65 years for malaria, lupus and other things,' he said.\",\n",
    "                    \"I think it gives you an additional level of safety, but you can ask many doctors are in favor of it. Many front line workers won’t go there, unless they have the hydroxy. the President continued.\",\n",
    "                    \"Yesterday, Senate Minority Leader Chuck Schumer claimed that Trump must have some financial interest in hydroxychloroquine, a claim that has previously been proven false. 'Maybe he has family or friends who own part of the company. It’s not unlike the president. Someone at Mar-A-Lago, calls him on the phone, tells him, ‘Oh, this is a good company,’ and he just talks about it. Maybe he did it to divert attention from all the bad things happening, and maybe he’s just lying.' Schumer told MSNBC’s Morning Joe.\",\n",
    "                    \"'This president doesn’t tell the truth. He may be taking this, may not,' Schumer also charged, echoing host Joe Scarborough who proclaimed that 'the president is not taking it, and yet, and yet, he’s telling Americans that they should take it.'\"]\n",
    "\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "MAX_LENGHT = 15\n",
    "tokens_unseen = tokenizer.batch_encode_plus(\n",
    "    unseen_news_text,\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "unseen_seq = torch.tensor(tokens_unseen['input_ids'])\n",
    "unseen_mask = torch.tensor(tokens_unseen['attention_mask'])\n",
    "\n",
    "with torch.no_grad():\n",
    "  preds = model(unseen_seq, unseen_mask)\n",
    "  preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vooQxtj5UBt-",
    "outputId": "6ec9205c-76bf-4a24-9366-961994ec4ba8"
   },
   "outputs": [],
   "source": [
    "# testing on unseen data\n",
    "unseen_news_text = [\n",
    "                    \"Donald Trump Sends Out Embarrassing New Year’s Eve Message; This is Disturbing\",     # Fake\n",
    "                    \"WATCH: George W. Bush Calls Out Trump For Supporting White Supremacy\",               # Fake\n",
    "                    \"U.S. lawmakers question businessman at 2016 Trump Tower meeting: sources\",           # True\n",
    "                    \"Elections cancelled in India\",                        # True\n",
    "                   ]\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "MAX_LENGHT = 15\n",
    "tokens_unseen = tokenizer.batch_encode_plus(\n",
    "    unseen_news_text,\n",
    "    max_length = MAX_LENGHT,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "unseen_seq = torch.tensor(tokens_unseen['input_ids'])\n",
    "unseen_mask = torch.tensor(tokens_unseen['attention_mask'])\n",
    "\n",
    "with torch.no_grad():\n",
    "  preds = model(unseen_seq, unseen_mask)\n",
    "  preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MVTchX_jGTT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"C:\\\\Users\\\\SOT-4\\\\Desktop\\\\vamsi\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Define the path to save the model\n",
    "save_path = os.path.join(directory, \"dhruval.pth\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYNivn3nkOgU"
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/content/dhruval.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xJoxqQWjGWH"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/dhruval_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfEvUUmmjGbW",
    "outputId": "4ec2381f-2bcd-409d-a1d7-4144529d75b2"
   },
   "outputs": [],
   "source": [
    "loaded_model = torch.load('/content/dhruval.pth')\n",
    "\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4BkCkN9jGds",
    "outputId": "a1dacc8f-1172-46d8-92ce-785e0ccce8e9"
   },
   "outputs": [],
   "source": [
    "# Tokenize and encode sequences in the test set\n",
    "unseen_news_text = [\"Second court rejects Trump bid to stop transgender military recruits\"]\n",
    "MAX_LENGTH = 150\n",
    "tokens_unseen = tokenizer.batch_encode_plus(\n",
    "    unseen_news_text,\n",
    "    max_length=MAX_LENGTH,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "unseen_seq = torch.tensor(tokens_unseen['input_ids'])\n",
    "unseen_mask = torch.tensor(tokens_unseen['attention_mask'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = loaded_model(unseen_seq, unseen_mask)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "preds = np.argmax(preds, axis=1)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jOmLzyHHWtD"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xB7rUfs8HdPd",
    "outputId": "1d6efe88-b7b3-4657-9ea9-752470c5cc8e"
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYk0LhLCLhU0",
    "outputId": "67f8e993-4fc3-4403-bfd8-4aef1d645cc9"
   },
   "outputs": [],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vneZfoC2Lhfr",
    "outputId": "23ff9c61-21f3-4103-ecc0-0f77258fc003"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "bPSSyY1yH42o",
    "outputId": "196e73b9-d1ee-4ebc-f660-504e36804a0c"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "true_data = pd.read_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/a1_True.csv')\n",
    "fake_data = pd.read_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/a2_Fake.csv')\n",
    "\n",
    "# Generate labels True/Fake under new Target Column in 'true_data' and 'fake_data'\n",
    "true_data['Target'] = 'True'\n",
    "fake_data['Target'] = 'Fake'\n",
    "\n",
    "# Merge 'true_data' and 'fake_data', by random mixing into a single df called 'data'\n",
    "data = pd.concat([true_data, fake_data]).sample(frac=1).reset_index().drop(columns=['index'])\n",
    "\n",
    "# See how the data looks like\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPxQ9vZzH45y"
   },
   "outputs": [],
   "source": [
    "# Target column is made of string values True/Fake, let's change it to numbers 0/1 (Fake=1)\n",
    "data['label'] = pd.get_dummies(data.Target)['Fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "izfFeFIVIzOj",
    "outputId": "a911f02a-4a72-467c-8a7c-49d497820501"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "iWqPsCm4JE3F",
    "outputId": "84ec9109-051c-4a2a-cb29-f750ca282f5d"
   },
   "outputs": [],
   "source": [
    "# Checking if our data is well balanced\n",
    "label_size = [data['label'].sum(),len(data['label'])-data['label'].sum()]\n",
    "plt.pie(label_size,explode=[0.1,0.1],colors=['firebrick','navy'],startangle=90,shadow=True,labels=['Fake','True'],autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tE9_GW56JE5n"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8n2n-KFoJE8I"
   },
   "outputs": [],
   "source": [
    "# Train-Validation-Test set split into 70:15:15 ratio\n",
    "# Train-Temp split\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(data['title'], data['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=data['Target'])\n",
    "# Validation-Test split\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JbNruoxJE-W"
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({'title': train_text, 'label': train_labels})\n",
    "val_data = pd.DataFrame({'title': val_text, 'label': val_labels})\n",
    "test_data = pd.DataFrame({'title': test_text, 'label': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGc4FI0eKH3f"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrames to CSV files\n",
    "train_data.to_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/train.csv', index=False)\n",
    "val_data.to_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/val.csv', index=False)\n",
    "test_data.to_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNie_4FaKgMw",
    "outputId": "e9eca550-2b1f-45b0-8b94-bd2cb8c20914"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data['title'])\n",
    "X_val_tfidf = vectorizer.transform(val_data['title'])\n",
    "X_test_tfidf = vectorizer.transform(test_data['title'])\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_tfidf, train_data['label'])\n",
    "\n",
    "# Validate the model\n",
    "val_predictions = svm_model.predict(X_val_tfidf)\n",
    "val_accuracy = accuracy_score(val_data['label'], val_predictions)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "# Test the model\n",
    "test_predictions = svm_model.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(test_data['label'], test_predictions)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGnZI4k3yGCn",
    "outputId": "84f43614-fd8a-4a2c-e196-19682d5b22a0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming val_labels are your true labels from the validation set\n",
    "y_true = val_labels\n",
    "y_pred = svm_model.predict(X_val_tfidf)  # Predicted labels from the SVM model\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate True Positives, False Positives, False Negatives for each class\n",
    "true_positives = np.diag(conf_matrix)\n",
    "false_positives = np.sum(conf_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(conf_matrix, axis=1) - true_positives\n",
    "\n",
    "# Calculate Precision, Recall, F1-score for each class\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate macro-averaged precision, recall, F1-score\n",
    "macro_precision = np.mean(precision)\n",
    "macro_recall = np.mean(recall)\n",
    "macro_f1_score = np.mean(f1_score)\n",
    "\n",
    "# Calculate weighted-averaged precision, recall, F1-score\n",
    "support = np.sum(conf_matrix, axis=1)  # Number of true instances for each class\n",
    "weighted_precision = np.sum(precision * support) / np.sum(support)\n",
    "weighted_recall = np.sum(recall * support) / np.sum(support)\n",
    "weighted_f1_score = np.sum(f1_score * support) / np.sum(support)\n",
    "\n",
    "# Print results\n",
    "print(\"Precision, Recall, F1-score for each class:\")\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {precision[i]:.3f}\")\n",
    "    print(f\"  Recall: {recall[i]:.3f}\")\n",
    "    print(f\"  F1-score: {f1_score[i]:.3f}\")\n",
    "\n",
    "print(\"\\nMacro-averaged metrics:\")\n",
    "print(f\"Macro-averaged Precision: {macro_precision:.3f}\")\n",
    "print(f\"Macro-averaged Recall: {macro_recall:.3f}\")\n",
    "print(f\"Macro-averaged F1-score: {macro_f1_score:.3f}\")\n",
    "\n",
    "print(\"\\nWeighted-averaged metrics:\")\n",
    "print(f\"Weighted-averaged Precision: {weighted_precision:.3f}\")\n",
    "print(f\"Weighted-averaged Recall: {weighted_recall:.3f}\")\n",
    "print(f\"Weighted-averaged F1-score: {weighted_f1_score:.3f}\")\n",
    "\n",
    "# Additional metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCvxe2kbMmwN",
    "outputId": "9c00c380-ae04-4941-c73b-c7f9c7d7776e"
   },
   "outputs": [],
   "source": [
    "# Example input sentence\n",
    "input_sentence = \"Factbox: Trump U.S. Supreme Court pick could affect pending cases\"\n",
    "\n",
    "# Preprocess and vectorize the input sentence\n",
    "input_sentence_tfidf = vectorizer.transform([input_sentence])\n",
    "\n",
    "# Predict using trained SVM model\n",
    "predicted_label = svm_model.predict(input_sentence_tfidf)\n",
    "\n",
    "# Print the predicted label\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Label: {predicted_label[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xI827HQwM8Si",
    "outputId": "1b54d2b0-8d6f-483a-84be-5403bf7bbe7c"
   },
   "outputs": [],
   "source": [
    "# List of input sentences\n",
    "input_sentences = [\n",
    "    \"Jones certified U.S. Senate winner despite Moore challenge\"\n",
    "]\n",
    "\n",
    "# Preprocess and vectorize the input sentences\n",
    "input_sentences_tfidf = vectorizer.transform(input_sentences)\n",
    "\n",
    "# Predict using trained SVM model\n",
    "predicted_labels = svm_model.predict(input_sentences_tfidf)\n",
    "\n",
    "# Print the predicted labels for each input sentence\n",
    "for sentence, label in zip(input_sentences, predicted_labels):\n",
    "    # Print 1 for True and 0 for False\n",
    "    print(f\"Input Sentence: {sentence}\")\n",
    "    print(f\"Predicted Label: {1 if label else 0}\")\n",
    "    print()  # Print a blank line for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyJZVBXHvC_K",
    "outputId": "cb7ef6b0-8c0a-4d69-f5a9-ff62f8146b7e"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# Define the pipeline with TF-IDF vectorizer and SVM classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000)),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Fit the pipeline with your training data\n",
    "pipeline.fit(train_data['title'], train_data['label'])\n",
    "\n",
    "# Save the pipeline to a file\n",
    "model_filename = '/content/drive/MyDrive/Project11_FakeNewsDetection/svm_model_pipeline.pkl'\n",
    "joblib.dump(pipeline, model_filename)\n",
    "\n",
    "print(f\"Pipeline saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AXVHcdewO4O",
    "outputId": "6f511732-8da1-4387-cbb0-f2f8230d5a77"
   },
   "outputs": [],
   "source": [
    "# Load the saved pipeline using pickle\n",
    "with open(pipeline_file_path, 'rb') as f:\n",
    "    loaded_pipeline = pickle.load(f)\n",
    "\n",
    "# Example test data\n",
    "X_test = test_data['title'].astype(str)  # Assuming you have test_data defined similarly\n",
    "\n",
    "# Predict using the loaded pipeline\n",
    "y_pred = loaded_pipeline.predict(X_test)\n",
    "\n",
    "# Print or use y_pred as needed\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dlq-X5_Q7--r"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVXhIskX8EdX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/train.csv')\n",
    "val_data = pd.read_csv('/content/drive/MyDrive/Project11_FakeNewsDetection/val.csv')\n",
    "\n",
    "# Remove duplicate rows\n",
    "train_data = train_data.drop_duplicates()\n",
    "val_data = val_data.drop_duplicates()\n",
    "\n",
    "# Tokenize and pad the text data\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the maximum number of words and maximum sequence length\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_data['title'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['title'])\n",
    "X_val = tokenizer.texts_to_sequences(val_data['title'])\n",
    "\n",
    "# Pad the sequences\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_val = pad_sequences(X_val, maxlen=max_len)\n",
    "\n",
    "# Get the labels\n",
    "y_train = train_data['label'].values\n",
    "y_val = val_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2pXL8808fZr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUp8PZmU8fcL",
    "outputId": "83259cb2-0620-4669-f723-e7c623d8bce9"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V46LJ1uXZ7F",
    "outputId": "04dbbad2-7e86-4d6e-b592-422a104a4f32"
   },
   "outputs": [],
   "source": [
    "# Save the trained model using joblib\n",
    "lstm_model_path = '/content/drive/MyDrive/Project11_FakeNewsDetection/lstm_model.pkl'\n",
    "joblib.dump(model, lstm_model_path)\n",
    "\n",
    "print(f\"Saved LSTM model at {lstm_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Zj5h7QbnZC0t"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00b71de03f394bce8e26aca0bc039fce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01105dc7948e4d1da175ad5a72f67be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a641a87c82ab487eaa8b5fbaa25086c4",
      "placeholder": "​",
      "style": "IPY_MODEL_ff797e3b2ea3468e8dea8e1de0332447",
      "value": "vocab.txt: 100%"
     }
    },
    "06e168be066246d58f5d5273df615830": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13db723e63a2436f99b0a5cfba38c21a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17d0c41df95246b5ad1e7fae74c6a655": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b5931713a9c4f538a2520f6ab2870b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a20a073132fd4cc8a01b21553fb9aa76",
      "placeholder": "​",
      "style": "IPY_MODEL_bf595f72c0b943b0ae8a0a7f1b777d88",
      "value": " 570/570 [00:00&lt;00:00, 19.7kB/s]"
     }
    },
    "1e68a6d6c1594de698c67bebc5fc23e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2cf993269d34a5fa7c066f9fd54b2da",
      "placeholder": "​",
      "style": "IPY_MODEL_2b3ae4df3a7e4689aa4bd6910b8d0ff5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "268307f55e24412d8ef78c689dd2e87e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa723e6b0f1c41d0ba78ae1da8817721",
      "placeholder": "​",
      "style": "IPY_MODEL_e86fece3830248f1a8b2e4ebc31e76a8",
      "value": " 466k/466k [00:00&lt;00:00, 22.2MB/s]"
     }
    },
    "2699fa609bd8489eba4e2cb4bcb9b15e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26d397d831e443e49c8d0210d082a872": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b3ae4df3a7e4689aa4bd6910b8d0ff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3be6b9cae1d94e039313b8bac77fa1a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_942137c329824fc28a38a31d0303c6e0",
      "placeholder": "​",
      "style": "IPY_MODEL_9a2b81dba4ba4753836fc9cf54595de1",
      "value": " 48.0/48.0 [00:00&lt;00:00, 2.80kB/s]"
     }
    },
    "3ef7c3f322f44340945cea9c4f9759e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01105dc7948e4d1da175ad5a72f67be3",
       "IPY_MODEL_f165a6209a6c4009b71914404abbb46c",
       "IPY_MODEL_cedbfb33c01d4600837ee1335372afd4"
      ],
      "layout": "IPY_MODEL_7f1b6de7125340f796d295a204cabfb0"
     }
    },
    "423788e1720149cb92c60ccd61557bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45ce25fdc623489c9bf475ec242de7b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49a98967c1b04064a933bbf66f946281": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a4bf3ae22bc4b35b3bf7a733e34654e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fb7c223713f44cb87a36ba7a086cf43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "538765f161f143f0ad7cd6e9172af578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e18e2682f044ee5b5d56e2fd004aa80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06e168be066246d58f5d5273df615830",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_697306d0a6c040f49562331b8c0d10f8",
      "value": 466062
     }
    },
    "64bfacc65e0e45629c5086b03027e8d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67eac869bd3d4900a4c727ecc2ff2b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c686b67b6b2641c182d4d83b8f6c5166",
       "IPY_MODEL_9c08a2ba28244c1a8d8707de5c0e86c7",
       "IPY_MODEL_1b5931713a9c4f538a2520f6ab2870b6"
      ],
      "layout": "IPY_MODEL_e4996cc2b72f4a10a12fe6c68549b5ae"
     }
    },
    "697306d0a6c040f49562331b8c0d10f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b934af7736942c6bf4d7ca6f4213a08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71c292121be3480591c1fc8e79331aba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f1b6de7125340f796d295a204cabfb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87d6dccb51ac4d8093b976849d5662a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a4bf3ae22bc4b35b3bf7a733e34654e",
      "placeholder": "​",
      "style": "IPY_MODEL_bd403ae42dbc40a3a406539fe168f278",
      "value": " 440M/440M [00:01&lt;00:00, 246MB/s]"
     }
    },
    "8e76d567611041d7a4c1c735d89d79f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9057c0d2cbf94328aa27dca52285beb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9319116705be4dbb9a5892134bc6942a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00b71de03f394bce8e26aca0bc039fce",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b199e5753c2344a48246d195a0107b63",
      "value": 440449768
     }
    },
    "942137c329824fc28a38a31d0303c6e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a2b81dba4ba4753836fc9cf54595de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a8bad0c752246dc9e640dcc3d4a16dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c08a2ba28244c1a8d8707de5c0e86c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71c292121be3480591c1fc8e79331aba",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64bfacc65e0e45629c5086b03027e8d6",
      "value": 570
     }
    },
    "a20a073132fd4cc8a01b21553fb9aa76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a641a87c82ab487eaa8b5fbaa25086c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa723e6b0f1c41d0ba78ae1da8817721": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b199e5753c2344a48246d195a0107b63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bd403ae42dbc40a3a406539fe168f278": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf595f72c0b943b0ae8a0a7f1b777d88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c686b67b6b2641c182d4d83b8f6c5166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26d397d831e443e49c8d0210d082a872",
      "placeholder": "​",
      "style": "IPY_MODEL_4fb7c223713f44cb87a36ba7a086cf43",
      "value": "config.json: 100%"
     }
    },
    "cedbfb33c01d4600837ee1335372afd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2699fa609bd8489eba4e2cb4bcb9b15e",
      "placeholder": "​",
      "style": "IPY_MODEL_9a8bad0c752246dc9e640dcc3d4a16dd",
      "value": " 232k/232k [00:00&lt;00:00, 10.1MB/s]"
     }
    },
    "d9a9159f5fc24e4f94a8cea2203f21d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13db723e63a2436f99b0a5cfba38c21a",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9057c0d2cbf94328aa27dca52285beb4",
      "value": 48
     }
    },
    "e03a712bd0d5472db8b023bd7b2f5a61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec45badd3b11427f9d4b09ec4329300f",
      "placeholder": "​",
      "style": "IPY_MODEL_423788e1720149cb92c60ccd61557bef",
      "value": "model.safetensors: 100%"
     }
    },
    "e2cf993269d34a5fa7c066f9fd54b2da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4996cc2b72f4a10a12fe6c68549b5ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e86fece3830248f1a8b2e4ebc31e76a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb4997d9e32240c3b2d65268c06a1570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e03a712bd0d5472db8b023bd7b2f5a61",
       "IPY_MODEL_9319116705be4dbb9a5892134bc6942a",
       "IPY_MODEL_87d6dccb51ac4d8093b976849d5662a3"
      ],
      "layout": "IPY_MODEL_17d0c41df95246b5ad1e7fae74c6a655"
     }
    },
    "ec45badd3b11427f9d4b09ec4329300f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef303360020b4248ba7a5787d06d66d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f165a6209a6c4009b71914404abbb46c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45ce25fdc623489c9bf475ec242de7b7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef303360020b4248ba7a5787d06d66d3",
      "value": 231508
     }
    },
    "f5f45d1ca82b45dd9d61d9b6d8398d43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e68a6d6c1594de698c67bebc5fc23e9",
       "IPY_MODEL_d9a9159f5fc24e4f94a8cea2203f21d6",
       "IPY_MODEL_3be6b9cae1d94e039313b8bac77fa1a7"
      ],
      "layout": "IPY_MODEL_49a98967c1b04064a933bbf66f946281"
     }
    },
    "fa2cc9cecff8401ba42db041f275970f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b934af7736942c6bf4d7ca6f4213a08",
      "placeholder": "​",
      "style": "IPY_MODEL_8e76d567611041d7a4c1c735d89d79f4",
      "value": "tokenizer.json: 100%"
     }
    },
    "feb70516cd204bafa3e631cbca6fb717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa2cc9cecff8401ba42db041f275970f",
       "IPY_MODEL_5e18e2682f044ee5b5d56e2fd004aa80",
       "IPY_MODEL_268307f55e24412d8ef78c689dd2e87e"
      ],
      "layout": "IPY_MODEL_538765f161f143f0ad7cd6e9172af578"
     }
    },
    "ff797e3b2ea3468e8dea8e1de0332447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
