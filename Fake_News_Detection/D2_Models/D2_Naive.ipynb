{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "Oc-b5A_Ia5nK",
        "UqBbrNpCcPTl",
        "AQjWcsV9d07f",
        "3Xq7FNdtfT_Z"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a1f703194854a3fb803be5ebd257631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_376df975828e4ee7920cec68291e954c",
              "IPY_MODEL_55ffa10da6cc483fabfe2a57c8c497b8",
              "IPY_MODEL_675778c69a3e4b9a9a3fcb75774842fe"
            ],
            "layout": "IPY_MODEL_7f65e65c74d042bfa691f707a647b9c7"
          }
        },
        "376df975828e4ee7920cec68291e954c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c11f1ded408474cb96341c01db9f713",
            "placeholder": "​",
            "style": "IPY_MODEL_fa2e919358b24c8699264b280adc046b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "55ffa10da6cc483fabfe2a57c8c497b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0eb69180ba4322a59e6319c8b2df03",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f68efcad8f447c1bb4fdb070231df99",
            "value": 48
          }
        },
        "675778c69a3e4b9a9a3fcb75774842fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a817cd8c014dfbb2e0ee9ac18f6f53",
            "placeholder": "​",
            "style": "IPY_MODEL_497a8ae236b84168b2b3ae284e0f06c1",
            "value": " 48.0/48.0 [00:00&lt;00:00, 873B/s]"
          }
        },
        "7f65e65c74d042bfa691f707a647b9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c11f1ded408474cb96341c01db9f713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa2e919358b24c8699264b280adc046b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b0eb69180ba4322a59e6319c8b2df03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f68efcad8f447c1bb4fdb070231df99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6a817cd8c014dfbb2e0ee9ac18f6f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497a8ae236b84168b2b3ae284e0f06c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b72ab50b66564c86ba4083de37872526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f489e3686c14c8d8f1cfdff68e09ff5",
              "IPY_MODEL_d76d19e74a9841b7959dd79cc6e90cfc",
              "IPY_MODEL_aa962a406a514ee290cbf300be2009af"
            ],
            "layout": "IPY_MODEL_6800c498cde940be98fb96465693dbd2"
          }
        },
        "8f489e3686c14c8d8f1cfdff68e09ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f33616ebe14ae980f097529fe311f2",
            "placeholder": "​",
            "style": "IPY_MODEL_692d182c6fba49f98f8344d95385aa2f",
            "value": "vocab.txt: 100%"
          }
        },
        "d76d19e74a9841b7959dd79cc6e90cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54f97dbf90140488652ccd4d34399cf",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df0b563d00864f05b76f14254a555b60",
            "value": 231508
          }
        },
        "aa962a406a514ee290cbf300be2009af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f14b73b08e346fc809f19b476b4a4cb",
            "placeholder": "​",
            "style": "IPY_MODEL_f9def4ec72034b3abc0ab64e446523f2",
            "value": " 232k/232k [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "6800c498cde940be98fb96465693dbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f33616ebe14ae980f097529fe311f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692d182c6fba49f98f8344d95385aa2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f54f97dbf90140488652ccd4d34399cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0b563d00864f05b76f14254a555b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f14b73b08e346fc809f19b476b4a4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9def4ec72034b3abc0ab64e446523f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6549e352aee4d2486f08c8804482b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d5a717c05234d928a09b44b286c1089",
              "IPY_MODEL_00da18999e7f45a991f2a8a1afeefc6f",
              "IPY_MODEL_fae8e6fb475f43bc8aa35d429c74ee15"
            ],
            "layout": "IPY_MODEL_095807d773fa436c9343b0efce2d6b03"
          }
        },
        "2d5a717c05234d928a09b44b286c1089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee76151674874571b868b1f425155a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_6ccc64a762644847ad84ef0e530449fa",
            "value": "tokenizer.json: 100%"
          }
        },
        "00da18999e7f45a991f2a8a1afeefc6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f241a437603c41e49d0e3c0c74153578",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93ff1a5c33ba4697aadd1435c90bc517",
            "value": 466062
          }
        },
        "fae8e6fb475f43bc8aa35d429c74ee15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e015ad0f0c4c3bb3b78e31ede9ad0c",
            "placeholder": "​",
            "style": "IPY_MODEL_0e7bba9dae2a45b4a3ac2299feef5da0",
            "value": " 466k/466k [00:00&lt;00:00, 5.02MB/s]"
          }
        },
        "095807d773fa436c9343b0efce2d6b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee76151674874571b868b1f425155a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccc64a762644847ad84ef0e530449fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f241a437603c41e49d0e3c0c74153578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ff1a5c33ba4697aadd1435c90bc517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3e015ad0f0c4c3bb3b78e31ede9ad0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7bba9dae2a45b4a3ac2299feef5da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgyYVCQkWMFq",
        "outputId": "24c22ca2-0f3c-4382-cc38-d29f623ba584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search CV\n"
      ],
      "metadata": {
        "id": "1vYVbd5rWIcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)\n",
        "\n",
        "# Define the pipeline with TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(max_features=500)),  # Reduce number of features for faster computation\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'nb__alpha': [0.1, 0.5, 1.0],  # Smoothing parameter\n",
        "    'nb__fit_prior': [True, False]  # Whether to learn class prior probabilities or not\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV with cross-validation on training data\n",
        "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and evaluate it on validation data\n",
        "best_pipeline = grid_search.best_estimator_\n",
        "y_pred = best_pipeline.predict(X_val)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.2%}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the best pipeline using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D2/D2_naive/gridsearch_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(best_pipeline, f)\n",
        "\n",
        "print(f\"Model saved at {model_save_path}\")\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Extract features and labels from test data\n",
        "X_test = test_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    loaded_pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_test_pred = loaded_pipeline.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics for the test set\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_test_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1-mckjvhA4g",
        "outputId": "c8b43bf1-b0cd-46b8-b528-3f2c0d07bb7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Best parameters: {'nb__alpha': 0.1, 'nb__fit_prior': True}\n",
            "Best cross-validation score: 63.92%\n",
            "Accuracy on validation set: 63.22%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.43      0.52       720\n",
            "           1       0.63      0.80      0.70       868\n",
            "\n",
            "    accuracy                           0.63      1588\n",
            "   macro avg       0.63      0.62      0.61      1588\n",
            "weighted avg       0.63      0.63      0.62      1588\n",
            "\n",
            "Confusion Matrix:\n",
            "[[311 409]\n",
            " [175 693]]\n",
            "Model saved at /content/drive/MyDrive/D2/D2_naive/gridsearch_pipeline.pkl\n",
            "Accuracy on test set: 39.15%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.24      0.31       714\n",
            "           1       0.37      0.59      0.46       553\n",
            "\n",
            "    accuracy                           0.39      1267\n",
            "   macro avg       0.40      0.41      0.38      1267\n",
            "weighted avg       0.40      0.39      0.37      1267\n",
            "\n",
            "Confusion Matrix:\n",
            "[[170 544]\n",
            " [227 326]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes Optimization"
      ],
      "metadata": {
        "id": "Oc-b5A_Ia5nK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73OHzZfWXab2",
        "outputId": "888e157c-0beb-419a-ec2c-259f2a0c5d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical\n",
        "import pickle\n",
        "\n",
        "# Paths to data files\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "model_save_path = '/content/drive/MyDrive/D2/bayes_pipeline1.pkl'\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['statement']\n",
        "y_train = train_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['statement']\n",
        "y_val = val_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from test data\n",
        "X_test = test_data['statement']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Define the pipeline with TF-IDF vectorizer and Naive Bayes model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(max_features=500)),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define the parameter space for Bayesian Optimization\n",
        "param_space = {\n",
        "    'nb__alpha': Real(1e-3, 1.0, prior='log-uniform'),\n",
        "    'nb__fit_prior': Categorical([True, False])\n",
        "}\n",
        "\n",
        "# Perform Bayesian Optimization with cross-validation on training data\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=pipeline,\n",
        "    search_spaces=param_space,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_iter=20,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the Bayesian Optimization\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and evaluate it on validation data\n",
        "best_pipeline = bayes_search.best_estimator_\n",
        "y_pred_val = best_pipeline.predict(X_val)\n",
        "\n",
        "# Print best parameters and evaluation metrics on validation set\n",
        "print(f\"Best parameters: {bayes_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {bayes_search.best_score_:.2%}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred_val):.2%}\")\n",
        "print(\"Classification Report (Validation Set):\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "print(\"Confusion Matrix (Validation Set):\")\n",
        "print(confusion_matrix(y_val, y_pred_val))\n",
        "\n",
        "# Save the best model using pickle\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(best_pipeline, f)\n",
        "print(f\"Model saved at {model_save_path}\")\n",
        "\n",
        "# Evaluate the saved model on the test set\n",
        "print(\"\\nEvaluating on Test Set:\")\n",
        "\n",
        "# Load the trained model\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    trained_model = pickle.load(f)\n",
        "\n",
        "# Predict using the loaded model\n",
        "y_pred_test = trained_model.predict(X_test)\n",
        "\n",
        "# Evaluate performance on test set\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test):.2%}\")\n",
        "print(\"Classification Report (Test Set):\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "print(\"Confusion Matrix (Test Set):\")\n",
        "print(confusion_matrix(y_test, y_pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG-ZGF4GXicf",
        "outputId": "5eecd04a-4cad-461e-8b3c-bbd9ae96aa3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best parameters: OrderedDict([('nb__alpha', 0.0390441783218696), ('nb__fit_prior', True)])\n",
            "Best cross-validation score: 63.92%\n",
            "Accuracy on validation set: 39.07%\n",
            "Classification Report (Validation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.24      0.31       714\n",
            "           1       0.37      0.59      0.46       553\n",
            "\n",
            "    accuracy                           0.39      1267\n",
            "   macro avg       0.40      0.41      0.38      1267\n",
            "weighted avg       0.40      0.39      0.37      1267\n",
            "\n",
            "Confusion Matrix (Validation Set):\n",
            "[[170 544]\n",
            " [228 325]]\n",
            "Model saved at /content/drive/MyDrive/D2/bayes_pipeline1.pkl\n",
            "\n",
            "Evaluating on Test Set:\n",
            "Accuracy on test set: 63.35%\n",
            "Classification Report (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.44      0.52       720\n",
            "           1       0.63      0.80      0.70       868\n",
            "\n",
            "    accuracy                           0.63      1588\n",
            "   macro avg       0.64      0.62      0.61      1588\n",
            "weighted avg       0.64      0.63      0.62      1588\n",
            "\n",
            "Confusion Matrix (Test Set):\n",
            "[[314 406]\n",
            " [176 692]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Population-based Training"
      ],
      "metadata": {
        "id": "UqBbrNpCcPTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.base import clone\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Initialize population\n",
        "population_size = 10\n",
        "population = []\n",
        "\n",
        "# Generate initial population with random hyperparameters\n",
        "for _ in range(population_size):\n",
        "    alpha = np.random.uniform(1e-3, 1.0)\n",
        "    fit_prior = np.random.choice([True, False])\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    population.append((model, alpha, fit_prior))\n",
        "\n",
        "# Define number of iterations for PBT\n",
        "iterations = 10\n",
        "\n",
        "# Perform PBT\n",
        "for iteration in range(iterations):\n",
        "    scores = []\n",
        "\n",
        "    # Evaluate each model in the population\n",
        "    for model, alpha, fit_prior in population:\n",
        "        y_pred = model.predict(X_val_tfidf)\n",
        "        score = accuracy_score(y_val, y_pred)\n",
        "        scores.append((score, model, alpha, fit_prior))\n",
        "\n",
        "    # Sort population based on score\n",
        "    scores.sort(reverse=True, key=lambda x: x[0])\n",
        "    top_half = scores[:population_size // 2]\n",
        "    bottom_half = scores[population_size // 2:]\n",
        "\n",
        "    # Update bottom half of the population\n",
        "    for i in range(len(bottom_half)):\n",
        "        _, top_model, top_alpha, top_fit_prior = top_half[i]\n",
        "        _, _, _, _ = bottom_half[i]\n",
        "\n",
        "        # Clone the top model and perturb its hyperparameters\n",
        "        new_alpha = np.clip(top_alpha * np.random.uniform(0.8, 1.2), 1e-3, 1.0)\n",
        "        new_fit_prior = np.random.choice([True, False]) if np.random.rand() < 0.5 else top_fit_prior\n",
        "\n",
        "        new_model = clone(top_model)\n",
        "        new_model.set_params(alpha=new_alpha, fit_prior=new_fit_prior)\n",
        "        new_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        population[population_size // 2 + i] = (new_model, new_alpha, new_fit_prior)\n",
        "\n",
        "# Select the best model from the final population\n",
        "best_model, best_alpha, best_fit_prior = max(population, key=lambda x: accuracy_score(y_val, x[0].predict(X_val_tfidf)))\n",
        "\n",
        "# Define a pipeline with vectorizer and best model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('nb', best_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the entire training data with best hyperparameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Print best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best fit_prior: {best_fit_prior}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the pipeline (including vectorizer and best model) using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D2/naive/pbt_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved at {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtrA2KP4c3xj",
        "outputId": "d7bbca12-1ad0-46aa-d0b9-9881a3075975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best alpha: 0.7533955582020955\n",
            "Best fit_prior: False\n",
            "Accuracy on validation set: 65.55%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64       720\n",
            "           1       0.70      0.64      0.67       868\n",
            "\n",
            "    accuracy                           0.66      1588\n",
            "   macro avg       0.66      0.66      0.65      1588\n",
            "weighted avg       0.66      0.66      0.66      1588\n",
            "\n",
            "Confusion Matrix:\n",
            "[[486 234]\n",
            " [313 555]]\n",
            "Pipeline saved at /content/drive/MyDrive/D2/naive/pbt_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming 'statement' is the column containing text data in the test dataset\n",
        "X_test = test_data['statement']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "model_load_path = '/content/drive/MyDrive/D2/naive/pbt_pipeline.pkl'\n",
        "with open(model_load_path, 'rb') as f:\n",
        "    pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5nOSiQPZydK",
        "outputId": "f2e6ad5c-7a0f-4869-cff7-e8aa5ab7fceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 65.55%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64       720\n",
            "           1       0.70      0.64      0.67       868\n",
            "\n",
            "    accuracy                           0.66      1588\n",
            "   macro avg       0.66      0.66      0.65      1588\n",
            "weighted avg       0.66      0.66      0.66      1588\n",
            "\n",
            "Confusion Matrix:\n",
            "[[486 234]\n",
            " [313 555]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic Algorithms"
      ],
      "metadata": {
        "id": "AQjWcsV9d07f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXM1hRoPd5Eu",
        "outputId": "8fe0ed39-cd1e-4ff4-8558-8fe150ac20be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/135.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.25.2)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Define the evaluation function for genetic algorithm\n",
        "def evaluate(individual):\n",
        "    alpha = individual[0]\n",
        "    fit_prior = bool(individual[1])\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    return (accuracy,)\n",
        "\n",
        "# Set up the genetic algorithm\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_float\", random.uniform, 1e-3, 1.0)\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_float, toolbox.attr_bool), n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=[1e-3, 0], up=[1.0, 1], eta=0.1, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "# Genetic Algorithm parameters\n",
        "population_size = 20\n",
        "generations = 40\n",
        "cxpb, mutpb = 0.5, 0.2\n",
        "\n",
        "# Initialize population\n",
        "population = toolbox.population(n=population_size)\n",
        "\n",
        "# Run the Genetic Algorithm\n",
        "result_population, logbook = algorithms.eaSimple(population, toolbox, cxpb, mutpb, generations,\n",
        "                                                 stats=None, halloffame=None, verbose=True)\n",
        "\n",
        "# Select the best individual\n",
        "best_individual = tools.selBest(result_population, k=1)[0]\n",
        "best_alpha = best_individual[0]\n",
        "best_fit_prior = bool(best_individual[1])\n",
        "\n",
        "# Train the best model on the training data\n",
        "best_model = MultinomialNB(alpha=best_alpha, fit_prior=best_fit_prior)\n",
        "best_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Define a pipeline with vectorizer and best model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('nb', best_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the entire training data with best hyperparameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Print best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best fit_prior: {best_fit_prior}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the pipeline (including vectorizer and best model) using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D2/naive/genetic_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved at {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVzI4gUXd4v2",
        "outputId": "52f11eeb-8467-40c2-d293-f8f1847e3f5b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen\tnevals\n",
            "0  \t20    \n",
            "1  \t12    \n",
            "2  \t11    \n",
            "3  \t12    \n",
            "4  \t11    \n",
            "5  \t17    \n",
            "6  \t6     \n",
            "7  \t9     \n",
            "8  \t16    \n",
            "9  \t10    \n",
            "10 \t11    \n",
            "11 \t14    \n",
            "12 \t12    \n",
            "13 \t11    \n",
            "14 \t10    \n",
            "15 \t14    \n",
            "16 \t15    \n",
            "17 \t12    \n",
            "18 \t10    \n",
            "19 \t14    \n",
            "20 \t15    \n",
            "21 \t11    \n",
            "22 \t12    \n",
            "23 \t11    \n",
            "24 \t13    \n",
            "25 \t12    \n",
            "26 \t11    \n",
            "27 \t11    \n",
            "28 \t10    \n",
            "29 \t7     \n",
            "30 \t14    \n",
            "31 \t8     \n",
            "32 \t10    \n",
            "33 \t14    \n",
            "34 \t14    \n",
            "35 \t9     \n",
            "36 \t8     \n",
            "37 \t16    \n",
            "38 \t7     \n",
            "39 \t6     \n",
            "40 \t14    \n",
            "Best alpha: 0.6927793527466417\n",
            "Best fit_prior: False\n",
            "Accuracy on validation set: 65.62%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64       720\n",
            "           1       0.70      0.64      0.67       868\n",
            "\n",
            "    accuracy                           0.66      1588\n",
            "   macro avg       0.66      0.66      0.66      1588\n",
            "weighted avg       0.66      0.66      0.66      1588\n",
            "\n",
            "Confusion Matrix:\n",
            "[[487 233]\n",
            " [313 555]]\n",
            "Pipeline saved at /content/drive/MyDrive/D2/naive/genetic_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming 'statement' is the column containing text data in the test dataset\n",
        "X_test = test_data['statement']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "model_load_path = '/content/drive/MyDrive/D2/naive/genetic_pipeline.pkl'\n",
        "with open(model_load_path, 'rb') as f:\n",
        "    pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO1vRvgeaSR7",
        "outputId": "aabbcf31-09da-4436-ea6e-70da423a1039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 65.62%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64       720\n",
            "           1       0.70      0.64      0.67       868\n",
            "\n",
            "    accuracy                           0.66      1588\n",
            "   macro avg       0.66      0.66      0.66      1588\n",
            "weighted avg       0.66      0.66      0.66      1588\n",
            "\n",
            "Confusion Matrix:\n",
            "[[487 233]\n",
            " [313 555]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperband"
      ],
      "metadata": {
        "id": "3Xq7FNdtfT_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0YVkqKufXrw",
        "outputId": "b206f879-ff1a-4123-a9a2-ab7ac834345b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from hyperopt import hp, tpe, Trials, fmin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Load the training dataset\n",
        "train_data_path = '/content/drive/MyDrive/D2/training.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_data_path = '/content/drive/MyDrive/D2/validation.csv'\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "\n",
        "# Extract features and labels from training data\n",
        "X_train = train_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_train = train_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Extract features and labels from validation data\n",
        "X_val = val_data['statement']  # Assuming 'statement' is the column containing text data\n",
        "y_val = val_data['label'].astype(int)  # Assuming 'label' is the column containing labels\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Define the evaluation function for hyperopt\n",
        "def evaluate(params):\n",
        "    alpha = params['alpha']\n",
        "    fit_prior = params['fit_prior']\n",
        "    model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    return -accuracy  # Minimize negative accuracy (maximize accuracy)\n",
        "\n",
        "# Define the search space\n",
        "space = {\n",
        "    'alpha': hp.loguniform('alpha', np.log(1e-3), np.log(1.0)),  # Smoothing parameter\n",
        "    'fit_prior': hp.choice('fit_prior', [True, False])  # Whether to learn class prior probabilities or not\n",
        "}\n",
        "\n",
        "# Perform hyperparameter optimization with Hyperopt\n",
        "trials = Trials()\n",
        "best = fmin(fn=evaluate,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=100,  # Number of trials\n",
        "            trials=trials)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_alpha = best['alpha']\n",
        "best_fit_prior = [True, False][best['fit_prior']]\n",
        "\n",
        "# Train the best model on the full training data with the best hyperparameters\n",
        "best_model = MultinomialNB(alpha=best_alpha, fit_prior=best_fit_prior)\n",
        "best_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Define a pipeline with vectorizer and best model\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('nb', best_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the entire training data with best hyperparameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model on validation data\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "# Print best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best fit_prior: {best_fit_prior}\")\n",
        "print(f\"Accuracy on validation set: {accuracy_score(y_val, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# Save the pipeline (including vectorizer and best model) using pickle\n",
        "model_save_path = '/content/drive/MyDrive/D2/naive/hyperband_pipeline.pkl'\n",
        "with open(model_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(f\"Pipeline saved at {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tufb-YivfjHp",
        "outputId": "d1fe6706-5df8-4abb-b4d4-b89c1124f730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 100/100 [00:06<00:00, 15.98trial/s, best loss: -0.6561712846347607]\n",
            "Best alpha: 0.7247052253441295\n",
            "Best fit_prior: False\n",
            "Accuracy on validation set: 65.62%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64       720\n",
            "           1       0.70      0.64      0.67       868\n",
            "\n",
            "    accuracy                           0.66      1588\n",
            "   macro avg       0.66      0.66      0.66      1588\n",
            "weighted avg       0.66      0.66      0.66      1588\n",
            "\n",
            "Confusion Matrix:\n",
            "[[487 233]\n",
            " [313 555]]\n",
            "Pipeline saved at /content/drive/MyDrive/D2/naive/hyperband_pipeline.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming 'statement' is the column containing text data in the test dataset\n",
        "X_test = test_data['statement']\n",
        "y_test = test_data['label'].astype(int)\n",
        "\n",
        "# Load the saved pipeline\n",
        "model_load_path = '/content/drive/MyDrive/D2/naive/hyperband_pipeline.pkl'\n",
        "with open(model_load_path, 'rb') as f:\n",
        "    pipeline = pickle.load(f)\n",
        "\n",
        "# Make predictions using the pipeline\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xryly_dubB4t",
        "outputId": "29757bb2-7fb1-43cc-f7fb-6d3b1bd6c52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 38.75%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.40      0.42       714\n",
            "           1       0.32      0.37      0.35       553\n",
            "\n",
            "    accuracy                           0.39      1267\n",
            "   macro avg       0.39      0.39      0.39      1267\n",
            "weighted avg       0.40      0.39      0.39      1267\n",
            "\n",
            "Confusion Matrix:\n",
            "[[284 430]\n",
            " [346 207]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT + Grid"
      ],
      "metadata": {
        "id": "uBUfemcQfWeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pickle"
      ],
      "metadata": {
        "id": "q2LipWTguHAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Extract features and labels from test data\n",
        "X_test = test_data['statement']\n",
        "y_test = test_data['label'].astype(int)"
      ],
      "metadata": {
        "id": "H5eeGgpJuKQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict_path = '/content/drive/MyDrive/D2/bert_model/bert_model.pth'\n",
        "state_dict = torch.load(state_dict_path)\n",
        "\n",
        "# Print the keys in the state dictionary\n",
        "print(\"State Dictionary Keys:\")\n",
        "for key in state_dict.keys():\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i4GananIwcnd",
        "outputId": "ac820765-7e6a-4975-de99-2b68304e5c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Dictionary Keys:\n",
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Define the BERTClassifier class according to the saved model architecture\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.classifier = torch.nn.Linear(768, 2)  # This should match the saved model's classifier\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.classifier(pooled_output)\n",
        "        return torch.nn.functional.softmax(x, dim=1)\n",
        "\n",
        "# Load the BERT model and tokenizer\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "classifier_model = BERTClassifier(bert_model)\n",
        "\n",
        "# Load the state dict\n",
        "state_dict_path = '/content/drive/MyDrive/D2/bert_model/bert_model.pth'\n",
        "state_dict = torch.load(state_dict_path)\n",
        "\n",
        "# Load the state dict into the model\n",
        "classifier_model.load_state_dict(state_dict)\n",
        "classifier_model.eval()\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "6a1f703194854a3fb803be5ebd257631",
            "376df975828e4ee7920cec68291e954c",
            "55ffa10da6cc483fabfe2a57c8c497b8",
            "675778c69a3e4b9a9a3fcb75774842fe",
            "7f65e65c74d042bfa691f707a647b9c7",
            "8c11f1ded408474cb96341c01db9f713",
            "fa2e919358b24c8699264b280adc046b",
            "4b0eb69180ba4322a59e6319c8b2df03",
            "7f68efcad8f447c1bb4fdb070231df99",
            "f6a817cd8c014dfbb2e0ee9ac18f6f53",
            "497a8ae236b84168b2b3ae284e0f06c1",
            "b72ab50b66564c86ba4083de37872526",
            "8f489e3686c14c8d8f1cfdff68e09ff5",
            "d76d19e74a9841b7959dd79cc6e90cfc",
            "aa962a406a514ee290cbf300be2009af",
            "6800c498cde940be98fb96465693dbd2",
            "40f33616ebe14ae980f097529fe311f2",
            "692d182c6fba49f98f8344d95385aa2f",
            "f54f97dbf90140488652ccd4d34399cf",
            "df0b563d00864f05b76f14254a555b60",
            "0f14b73b08e346fc809f19b476b4a4cb",
            "f9def4ec72034b3abc0ab64e446523f2",
            "c6549e352aee4d2486f08c8804482b72",
            "2d5a717c05234d928a09b44b286c1089",
            "00da18999e7f45a991f2a8a1afeefc6f",
            "fae8e6fb475f43bc8aa35d429c74ee15",
            "095807d773fa436c9343b0efce2d6b03",
            "ee76151674874571b868b1f425155a6c",
            "6ccc64a762644847ad84ef0e530449fa",
            "f241a437603c41e49d0e3c0c74153578",
            "93ff1a5c33ba4697aadd1435c90bc517",
            "d3e015ad0f0c4c3bb3b78e31ede9ad0c",
            "0e7bba9dae2a45b4a3ac2299feef5da0"
          ]
        },
        "id": "uv0SHlO7wFQE",
        "outputId": "991efd29-e6ae-400c-dfcd-c9031f2df072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a1f703194854a3fb803be5ebd257631"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b72ab50b66564c86ba4083de37872526"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6549e352aee4d2486f08c8804482b72"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_bert(texts, batch_size=32):\n",
        "    predictions = []\n",
        "    num_batches = int(np.ceil(len(texts) / batch_size))\n",
        "    for i in range(num_batches):\n",
        "        batch_texts = texts[i*batch_size:(i+1)*batch_size]\n",
        "        batch_texts = batch_texts.tolist()\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "        logits = outputs\n",
        "        batch_predictions = torch.argmax(logits, dim=1).numpy()\n",
        "        predictions.extend(batch_predictions)\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "SulYtbcYuKWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved Naive Bayes pipeline\n",
        "model_save_path = '/content/drive/MyDrive/D2/D2_naive/gridsearch_pipeline.pkl'\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    nb_pipeline = pickle.load(f)"
      ],
      "metadata": {
        "id": "mP-Bq38JuKgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def predict_bert(texts, batch_size=32):\n",
        "    predictions = []\n",
        "    num_batches = int(np.ceil(len(texts) / batch_size))\n",
        "    for i in range(num_batches):\n",
        "        batch_texts = texts[i*batch_size:(i+1)*batch_size]\n",
        "        batch_texts = batch_texts.tolist()\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = classifier_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask']) # Use classifier_model instead of bert_model\n",
        "        logits = outputs # logits are now the output of the classifier\n",
        "        batch_predictions = torch.argmax(logits, dim=1).numpy()\n",
        "        predictions.extend(batch_predictions)\n",
        "    return np.array(predictions)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sGY_PrCSw6Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from both models\n",
        "nb_predictions = nb_pipeline.predict(X_test)\n",
        "bert_predictions = predict_bert(X_test)\n",
        "\n",
        "# Combine predictions using majority voting\n",
        "combined_predictions = np.array([np.bincount([nb_pred, bert_pred]).argmax() for nb_pred, bert_pred in zip(nb_predictions, bert_predictions)])\n",
        "\n",
        "# Print evaluation metrics for the test set\n",
        "print(f\"Accuracy on test set: {accuracy_score(y_test, combined_predictions):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, combined_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, combined_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZifVbbSuShm",
        "outputId": "dcd959c7-2d9b-4b5e-f0c6-e33581eada62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 39.38%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.26      0.33       714\n",
            "           1       0.37      0.57      0.45       553\n",
            "\n",
            "    accuracy                           0.39      1267\n",
            "   macro avg       0.40      0.41      0.39      1267\n",
            "weighted avg       0.41      0.39      0.38      1267\n",
            "\n",
            "Confusion Matrix:\n",
            "[[186 528]\n",
            " [240 313]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test with Batch Size"
      ],
      "metadata": {
        "id": "zDS40_GAuTRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pickle\n",
        "\n",
        "# Load the Naive Bayes pipeline\n",
        "model_save_path = '/content/drive/MyDrive/D2/D2_naive/gridsearch_pipeline.pkl'\n",
        "with open(model_save_path, 'rb') as f:\n",
        "    nb_pipeline = pickle.load(f)\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = '/content/drive/MyDrive/D2/testmod.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Sample a subset from the test data\n",
        "subset_size = 1000  # Define the size of the subset\n",
        "subset_data = test_data.sample(n=subset_size, random_state=42)\n",
        "\n",
        "# Extract features and labels from the subset\n",
        "X_test = subset_data['statement']\n",
        "y_test = subset_data['label'].astype(int)\n",
        "\n",
        "# Load and prepare BERT model and tokenizer\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.classifier = torch.nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        x = self.classifier(pooled_output)\n",
        "        return x\n",
        "\n",
        "# Load BERT model\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_model = BERTClassifier(bert_model)\n",
        "bert_model.load_state_dict(torch.load('/content/drive/MyDrive/D2/bert_model/bert_model.pth'))\n",
        "bert_model.eval()\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define prediction functions\n",
        "def predict_bert(texts):\n",
        "    texts = texts.tolist()  # Convert to a list of strings\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
        "    logits = outputs\n",
        "    return torch.argmax(logits, dim=1).numpy()\n",
        "\n",
        "def predict_naive_bayes(texts):\n",
        "    return nb_pipeline.predict(texts)\n",
        "\n",
        "# Batch processing\n",
        "batch_size = 100  # Adjust batch size according to your memory limits\n",
        "num_batches = int(np.ceil(len(X_test) / batch_size))\n",
        "\n",
        "combined_predictions = []\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start = i * batch_size\n",
        "    end = min((i + 1) * batch_size, len(X_test))\n",
        "    batch_texts = X_test[start:end]\n",
        "\n",
        "    bert_batch_predictions = predict_bert(batch_texts)\n",
        "    nb_batch_predictions = predict_naive_bayes(batch_texts)\n",
        "\n",
        "    for nb_pred, bert_pred in zip(nb_batch_predictions, bert_batch_predictions):\n",
        "        combined_predictions.append(np.bincount([nb_pred, bert_pred]).argmax())\n",
        "\n",
        "    # Clear cache to free up memory\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "combined_predictions = np.array(combined_predictions)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, combined_predictions)\n",
        "print(f\"Combined Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Print additional metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, combined_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, combined_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sguSDp7auW15",
        "outputId": "089611e9-76b3-4ab6-f38b-737ce23ede83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Accuracy: 38.70%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.26      0.33       577\n",
            "           1       0.36      0.56      0.44       423\n",
            "\n",
            "    accuracy                           0.39      1000\n",
            "   macro avg       0.40      0.41      0.38      1000\n",
            "weighted avg       0.41      0.39      0.37      1000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[150 427]\n",
            " [186 237]]\n"
          ]
        }
      ]
    }
  ]
}