{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Search CV"
      ],
      "metadata": {
        "id": "qb9qKvDdMbNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W9Xy5-3zccZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50747e82-76f0-46e2-b98d-4f56c62f0e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Extract features and labels\n",
        "X = data['text']\n",
        "y = data['label'].astype(int)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=500)  # Reduce number of features for faster computation\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Define the SVM model and a smaller parameter grid\n",
        "svm = SVC()\n",
        "param_grid = {\n",
        "    'C': [1, 10],\n",
        "    'gamma': [0.1, 0.01],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV with fewer folds\n",
        "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Get the best model and evaluate it\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_tfidf)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjvM9Q9EJUVu",
        "outputId": "8fc67f29-76d8-43eb-a328-6a01827a0b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "Best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Best cross-validation score: 0.9137013078708662\n",
            "Accuracy: 92.20%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       766\n",
            "           1       0.93      0.94      0.93      1118\n",
            "\n",
            "    accuracy                           0.92      1884\n",
            "   macro avg       0.92      0.92      0.92      1884\n",
            "weighted avg       0.92      0.92      0.92      1884\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 684   82]\n",
            " [  65 1053]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Save the best model\n",
        "model_path = '/content/drive/MyDrive/D3/D3_svm/hyper.pkl'\n",
        "joblib.dump(best_model, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3ceoFD_dVhg",
        "outputId": "08d89497-2585-442c-8d3e-433f82c35240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/D3/D3_svm/hyper.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes"
      ],
      "metadata": {
        "id": "yAO_Dsv2cEnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "ne9f3Clscczs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e838ae-1ced-483b-fc3d-a4ebef413036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/107.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.4.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import joblib\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Define the SVM model with a pipeline (optional: include scaling)\n",
        "model = make_pipeline(StandardScaler(with_mean=False), SVC())  # Set with_mean=False\n",
        "\n",
        "# Define parameter ranges for Bayesian optimization\n",
        "param_space = {\n",
        "    'svc__C': (1e-6, 100.0, 'log-uniform'),\n",
        "    'svc__gamma': (1e-6, 100.0, 'log-uniform'),\n",
        "    'svc__kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "# Perform Bayesian optimization\n",
        "opt = BayesSearchCV(\n",
        "    model,\n",
        "    param_space,\n",
        "    n_iter=5,  # Adjust the number of iterations as needed\n",
        "    cv=5,  # Cross-validation folds\n",
        "    n_jobs=-1,  # Use all available cores\n",
        "    verbose=1  # Print optimization progress\n",
        ")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data['text'])\n",
        "\n",
        "# Fit the optimizer on the transformed training data\n",
        "opt.fit(train_features, train_data['label'])\n",
        "# --- END_SOLUTION\n",
        "\n",
        "# Save the best SVM model\n",
        "import joblib\n",
        "\n",
        "save_path = '/content/drive/MyDrive/D3/D3_svm/bayesiansvm.pkl'\n",
        "joblib.dump(opt.best_estimator_, save_path)"
      ],
      "metadata": {
        "id": "6TpdKdmecfeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b107b8e5-ea3e-476d-917b-52622d7dfb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/D3/D3_svm/bayesiansvm.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "X_val = vectorizer.transform(val_data['text'])\n",
        "y_val = val_data['label']\n",
        "y_val_pred = opt.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Preprocess the test data\n",
        "X_test = vectorizer.transform(test_data['text'])\n",
        "y_test = test_data['label']\n",
        "y_test_pred = opt.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(\"Test Set Performance:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kavhq1GRdbiy",
        "outputId": "3a98036f-89b7-41f4-ec04-a37a1cda5dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.89      0.91       850\n",
            "           1       0.92      0.95      0.94      1168\n",
            "\n",
            "    accuracy                           0.93      2018\n",
            "   macro avg       0.93      0.92      0.93      2018\n",
            "weighted avg       0.93      0.93      0.93      2018\n",
            "\n",
            "Validation Accuracy: 0.9277\n",
            "Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.92       822\n",
            "           1       0.94      0.94      0.94      1196\n",
            "\n",
            "    accuracy                           0.93      2018\n",
            "   macro avg       0.93      0.93      0.93      2018\n",
            "weighted avg       0.93      0.93      0.93      2018\n",
            "\n",
            "Test Accuracy: 0.9316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PBT"
      ],
      "metadata": {
        "id": "Qi2KURKZcFEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Step 1: Load the datasets\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming your 'label' column needs encoding (if not binary already)\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['label'] = label_encoder.fit_transform(train_data['label'])\n",
        "val_data['label'] = label_encoder.transform(val_data['label'])\n",
        "test_data['label'] = label_encoder.transform(test_data['label'])\n",
        "\n",
        "# Step 2: Feature extraction (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_data['text'])\n",
        "X_val_tfidf = vectorizer.transform(val_data['text'])\n",
        "X_test_tfidf = vectorizer.transform(test_data['text'])\n",
        "y_train = train_data['label']\n",
        "y_val = val_data['label']\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Step 3: Train the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Step 4: Save the trained model\n",
        "model_save_path = '/content/drive/MyDrive/D3/D3_svm/pbt_svm.pkl'\n",
        "joblib.dump(svm_model, model_save_path)\n",
        "print(f\"Model saved successfully at {model_save_path}\")\n",
        "\n",
        "# Step 5: Evaluate the model's accuracy on validation data\n",
        "val_predictions = svm_model.predict(X_val_tfidf)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Step 6: Evaluate the model's accuracy on test data\n",
        "test_predictions = svm_model.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "8tidf3TQcdIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb9aa92-64ee-40c3-ef45-d2ff630d7529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at /content/drive/MyDrive/D3/D3_svm/pbt_svm.pkl\n",
            "Validation Accuracy: 0.9390\n",
            "Test Accuracy: 0.9430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "epOh4OGDcgHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic"
      ],
      "metadata": {
        "id": "LLTQl7gicFbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "i8y2kcatcdkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the datasets\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Assuming your 'label' column needs encoding (if not binary already)\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['label'] = label_encoder.fit_transform(train_data['label'])\n",
        "val_data['label'] = label_encoder.transform(val_data['label'])\n",
        "test_data['label'] = label_encoder.transform(test_data['label'])\n",
        "\n",
        "# Step 2: Feature extraction (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_data['text'])\n",
        "X_val_tfidf = vectorizer.transform(val_data['text'])\n",
        "X_test_tfidf = vectorizer.transform(test_data['text'])\n",
        "y_train = train_data['label']\n",
        "y_val = val_data['label']\n",
        "y_test = test_data['label']\n",
        "\n",
        "# Genetic Algorithm Settings\n",
        "population_size = 10\n",
        "num_generations = 5\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# Genetic Algorithm Framework\n",
        "population = []\n",
        "for _ in range(population_size):\n",
        "    # Randomly initialize SVM hyperparameters\n",
        "    C = np.random.uniform(0.1, 10.0)\n",
        "    kernel = np.random.choice(['linear', 'rbf'])\n",
        "    gamma = 'scale' if kernel == 'rbf' else 'auto'\n",
        "\n",
        "    # Train SVM with current hyperparameters\n",
        "    svm_model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)\n",
        "    svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Evaluate fitness on validation set\n",
        "    val_predictions = svm_model.predict(X_val_tfidf)\n",
        "    accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "    # Store hyperparameters and accuracy in population\n",
        "    population.append((svm_model, {'kernel': kernel, 'C': C, 'gamma': gamma}, accuracy))"
      ],
      "metadata": {
        "id": "N13JoAPQcdmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolution loop\n",
        "for generation in range(num_generations):\n",
        "    # Sort population by fitness (accuracy)\n",
        "    population.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Print the best model in the current generation\n",
        "    best_model, best_hyperparams, best_accuracy = population[0]\n",
        "    print(f\"Generation {generation + 1}: Best Accuracy = {best_accuracy:.4f}, Hyperparameters = {best_hyperparams}\")\n",
        "\n",
        "    # Select top performers to produce offspring\n",
        "    selected_parents = population[:population_size // 2]\n",
        "\n",
        "    # Crossover and mutation\n",
        "    offspring_population = []\n",
        "    for i in range(population_size):\n",
        "        parent1, params1, _ = selected_parents[np.random.randint(len(selected_parents))]\n",
        "        parent2, params2, _ = selected_parents[np.random.randint(len(selected_parents))]\n",
        "\n",
        "        # Perform crossover (combine hyperparameters)\n",
        "        child_params = {}\n",
        "        for param_key in params1.keys():\n",
        "            if np.random.rand() < 0.5:\n",
        "                child_params[param_key] = params1[param_key]\n",
        "            else:\n",
        "                child_params[param_key] = params2[param_key]\n",
        "\n",
        "        # Perform mutation (slight modification to hyperparameters)\n",
        "        for param_key in child_params.keys():\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                if param_key == 'C':\n",
        "                    child_params[param_key] = np.random.uniform(0.1, 10.0)\n",
        "                elif param_key == 'kernel':\n",
        "                    child_params[param_key] = np.random.choice(['linear', 'rbf'])\n",
        "                    if child_params[param_key] == 'rbf':\n",
        "                        child_params['gamma'] = 'scale'  # Adjust gamma for RBF kernel\n",
        "\n",
        "        # Train SVM with mutated hyperparameters\n",
        "        child_model = SVC(kernel=child_params['kernel'], C=child_params['C'], gamma=child_params['gamma'], random_state=42)\n",
        "        child_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        # Evaluate fitness on validation set\n",
        "        val_predictions = child_model.predict(X_val_tfidf)\n",
        "        accuracy = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "        # Add child to offspring population\n",
        "        offspring_population.append((child_model, child_params, accuracy))\n",
        "\n",
        "    # Replace the old population with the offspring\n",
        "    population = offspring_population"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrTSaCU-dmvI",
        "outputId": "b11c0e1b-bf28-46f4-b65e-778e4d963430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best Accuracy = 0.9470, Hyperparameters = {'kernel': 'rbf', 'C': 1.8480569904918551, 'gamma': 'scale'}\n",
            "Generation 2: Best Accuracy = 0.9475, Hyperparameters = {'kernel': 'rbf', 'C': 2.121405951856806, 'gamma': 'scale'}\n",
            "Generation 3: Best Accuracy = 0.9475, Hyperparameters = {'kernel': 'rbf', 'C': 2.121405951856806, 'gamma': 'scale'}\n",
            "Generation 4: Best Accuracy = 0.9475, Hyperparameters = {'kernel': 'rbf', 'C': 2.121405951856806, 'gamma': 'scale'}\n",
            "Generation 5: Best Accuracy = 0.9475, Hyperparameters = {'kernel': 'rbf', 'C': 2.121405951856806, 'gamma': 'scale'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final best model evaluation on test set\n",
        "population.sort(key=lambda x: x[2], reverse=True)\n",
        "best_model, best_hyperparams, best_accuracy = population[0]\n",
        "print(f\"Best Model - Accuracy on Validation Set: {best_accuracy:.4f}, Hyperparameters: {best_hyperparams}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_predictions = best_model.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Accuracy on Test Set: {test_accuracy:.4f}\")\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Final best model evaluation on test set\n",
        "population.sort(key=lambda x: x[2], reverse=True)\n",
        "best_model, best_hyperparams, best_accuracy = population[0]\n",
        "print(f\"Best Model - Accuracy on Validation Set: {best_accuracy:.4f}, Hyperparameters: {best_hyperparams}\")\n",
        "\n",
        "# Save the best model\n",
        "model_save_path = '/content/drive/MyDrive/D3/D3_svm/geneticsvm.pkl'\n",
        "joblib.dump(best_model, model_save_path)\n",
        "print(f\"Saved the best SVM model to {model_save_path}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_predictions = best_model.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Accuracy on Test Set: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBjugJbsdqXk",
        "outputId": "f225b7fa-1657-420f-97ce-a3b24e91a136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model - Accuracy on Validation Set: 0.9475, Hyperparameters: {'kernel': 'rbf', 'C': 2.121405951856806, 'gamma': 'scale'}\n",
            "Accuracy on Test Set: 0.9559\n",
            "Best Model - Accuracy on Validation Set: 0.9475, Hyperparameters: {'kernel': 'rbf', 'C': 2.121405951856806, 'gamma': 'scale'}\n",
            "Saved the best SVM model to /content/drive/MyDrive/D3/D3_svm/geneticsvm.pkl\n",
            "Accuracy on Test Set: 0.9559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperband"
      ],
      "metadata": {
        "id": "_B8N4DsXcFy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H2Rl32Lds6E",
        "outputId": "62d21817-47ae-45bc-ca9b-fd171d266c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.callbacks import VerboseCallback\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/D3/dataset/train.csv'\n",
        "val_data_path = '/content/drive/MyDrive/D3/dataset/val.csv'\n",
        "test_data_path = '/content/drive/MyDrive/D3/dataset/test.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "val_data = pd.read_csv(val_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "# ... (Your previous code) ...\n",
        "# Convert 'label' column to string type before using .str accessor\n",
        "train_data['label'] = train_data['label'].astype(str).str.lower().apply(lambda x: 1 if x == 'false' else 0)\n",
        "val_data['label'] = val_data['label'].astype(str).str.lower().apply(lambda x: 1 if x == 'false' else 0)\n",
        "test_data['label'] = test_data['label'].astype(str).str.lower().apply(lambda x: 1 if x == 'false' else 0)\n",
        "\n",
        "# --- Check label distribution AFTER conversion ---\n",
        "print(\"Train data labels after conversion:\", train_data['label'].value_counts())\n",
        "print(\"Validation data labels after conversion:\", val_data['label'].value_counts())\n",
        "# ... rest of your code\n",
        "# Combine train and val data for hyperparameter tuning\n",
        "X_train = train_data['text']\n",
        "y_train = train_data['label']\n",
        "X_val = val_data['text']\n",
        "y_val = val_data['label']\n",
        "\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = vectorizer.transform(X_val)\n",
        "\n",
        "# Define the parameter space for Hyperband\n",
        "param_space = {\n",
        "    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "    'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "    'degree': Integer(1, 8),  # Only used for 'poly' kernel\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfQYrD5HdtA2",
        "outputId": "ecbf4470-28f5-40a0-b6c8-d188ad4eaf5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data labels after conversion: label\n",
            "0    9416\n",
            "Name: count, dtype: int64\n",
            "Validation data labels after conversion: label\n",
            "0    2018\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique labels in training data\n",
        "print(y_train.unique())\n",
        "\n",
        "# Check distribution of labels\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_8WWsc4dtHS",
        "outputId": "836f97b4-d032-4f2a-9707-9558266998b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "label\n",
            "0    9416\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if you have more than one class in your training data\n",
        "if len(train_data['label'].unique()) <= 1:\n",
        "    print(\"WARNING: Your training data only has one class. This will cause errors with SVM.\")\n",
        "else:\n",
        "    print(\"You have multiple classes in your training data, you should be good to go!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8auGaiACdtXb",
        "outputId": "dad5a810-4d76-4082-df66-e4fcebeca6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Your training data only has one class. This will cause errors with SVM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.head())\n",
        "print(val_data.head())\n",
        "print(train_data['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st-Ax24bdtf5",
        "outputId": "6a5e024d-ab71-4fc6-e54d-c10a19d8f76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id                                              title           author  \\\n",
            "0  10724  Trumpâs FIRST Order: Anyone Burning An Ameri...     Martin Walsh   \n",
            "1   7200  Global Migration Meets Magic in Mohsin Hamidâ...  Alexandra Alter   \n",
            "2  19242  WATCH: Gingrich Accuses Megyn Kelly Of Being â...            Davis   \n",
            "3  11695  Badass Patriot Has MASSIVE Surprise For Thieve...      Amanda Shea   \n",
            "4   2205  James Wesley Rawles: âDouble Up On Your Prep...        Mac Slavo   \n",
            "\n",
            "                                                text  label  \n",
            "0  \\nPosted by Martin Walsh | Nov 11, 2016 | Libe...      0  \n",
            "1  In an unnamed,   city in the Muslim world, two...      0  \n",
            "2  Hillary Howls in Laughter About Radical Muslim...      0  \n",
            "3  Badass Patriot Has MASSIVE Surprise For Thieve...      0  \n",
            "4  \\nEnjoy your turkey, family events and holiday...      0  \n",
            "      id                                              title  \\\n",
            "0  11387        How WiFi & Other EMFs Cause Biological Harm   \n",
            "1   8187              US In Danger of Losing Allies In Asia   \n",
            "2  10600  Gorka: âThings Have Changed Fundamentallyâ...   \n",
            "3   1323  Thousands Of Buffalo Appear At Site Of Standin...   \n",
            "4  16734  RABBI SHMULEY: Will AIPAC Honor Trumpâs Defe...   \n",
            "\n",
            "                                  author  \\\n",
            "0  noreply@blogger.com (Alexander Light)   \n",
            "1                            Dave Hodges   \n",
            "2                           John Hayward   \n",
            "3                      Heather Callaghan   \n",
            "4                        Shmuley Boteach   \n",
            "\n",
            "                                                text  label  \n",
            "0  How WiFi & Other EMFs Cause Biological Harm Pr...      0  \n",
            "1  US In Danger of Losing Allies In Asia Philippi...      0  \n",
            "2  Former Breitbart News National Security Editor...      0  \n",
            "3  By Amanda Froelich [Recently], tensions betwee...      0  \n",
            "4  President Donald Trumpâs recent defense of I...      0  \n",
            "label\n",
            "0    9416\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Initialize the SVM model\n",
        "svc = SVC()\n",
        "\n",
        "# Stratified K-Fold for better class distribution in splits\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform Hyperband search with StratifiedKFold\n",
        "hyperband = BayesSearchCV(svc, param_space, n_iter=5, cv=skf, n_jobs=-1, random_state=42, scoring='accuracy')\n",
        "\n",
        "# Check if any fold has only one class\n",
        "for train_index, test_index in skf.split(X_train_tfidf, y_train):\n",
        "    if len(np.unique(y_train.iloc[train_index])) <= 1:\n",
        "        print(\"WARNING: A fold has only one class. This will cause errors with SVM.\")\n",
        "        break  # Stop if a problematic fold is found\n",
        "else:  # This block executes if no break occurred\n",
        "    try:\n",
        "        # Add verbose parameter to see the progress of the fitting process\n",
        "        hyperband.fit(X_train_tfidf, y_train, verbose=2) # Try fitting the model\n",
        "        # Print the best parameters found\n",
        "        print(f\"Best parameters found: {hyperband.best_params_}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model fitting: {e}\") # Print the error if fitting fails\n",
        "\n",
        "    # Save the best model\n",
        "    if hasattr(hyperband, 'best_estimator_'): # Check if the model was fit successfully\n",
        "        best_model = hyperband.best_estimator_\n",
        "        model_path = '/content/drive/MyDrive/D3/D3_svm/hyperbandsvm.pkl'\n",
        "        joblib.dump(best_model, model_path)\n",
        "    else:\n",
        "        print(\"Model fitting failed. Cannot save the best estimator.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCkm5NcjKGn4",
        "outputId": "2d392458-d780-44dd-908b-6bba67cd54f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: A fold has only one class. This will cause errors with SVM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "y_val_pred = best_model.predict(X_val_tfidf)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# Preprocess the test data\n",
        "X_test = test_data['text']\n",
        "y_test = test_data['label']\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_test_pred = best_model.predict(X_test_tfidf)\n",
        "print(\"Test Set Performance:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "hR4b-5QkceFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce21042-0719-4015-a57b-ac6c0c86c0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.42      0.59      2018\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.42      2018\n",
            "   macro avg       0.50      0.21      0.29      2018\n",
            "weighted avg       1.00      0.42      0.59      2018\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.58      2018\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.40      2018\n",
            "   macro avg       0.50      0.20      0.29      2018\n",
            "weighted avg       1.00      0.40      0.58      2018\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "Qi2KURKZcFEq",
        "LLTQl7gicFbC",
        "_B8N4DsXcFy4"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}